{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Three: Predicting Cancer Using A Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabe Gibitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA COLLECTION & PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose a data set of more than 200,000 images, all cropped to 50x50 in RGB. \n",
    "\n",
    "Images, in the eyes of a computer, are simply a list of numbers. This means that each image in my set has three layers, the R, the G and the B. Each of these layers is given a number. The data came from 162 slides that were scanned at 40x.\n",
    "\n",
    "These images were divided into dozens of folders, each having a '0' folder and a '1' folder. The 0 folder contained images with no cancerous cells, while the 1 folder contained images that were cancerous.\n",
    "\n",
    "Most of the hard work was done, but I needed to aggregate all images into two folders:\n",
    "1. Folder 0\n",
    "2. Folder 1\n",
    "\n",
    "Let's use Python to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients = os.listdir('data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('data/raw_data/9036/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#For 0 folder:\\nfor folder in patients:\\n    imagelist = os.listdir('data/raw_data/{}/0'.format(folder))\\n    for image in imagelist:\\n        shutil.copyfile('data/raw_data/{}/0/{}'.format(folder, image), 'data/0/{}'.format(image))\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#For 0 folder:\n",
    "for folder in patients:\n",
    "    imagelist = os.listdir('data/raw_data/{}/0'.format(folder))\n",
    "    for image in imagelist:\n",
    "        shutil.copyfile('data/raw_data/{}/0/{}'.format(folder, image), 'data/0/{}'.format(image))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#For 1 folder:\\nfor folder in patients:\\n    imagelist = os.listdir('data/raw_data/{}/1'.format(folder))\\n    for image in imagelist:\\n        shutil.copyfile('data/raw_data/{}/1/{}'.format(folder, image), 'data/1/{}'.format(image))\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#For 1 folder:\n",
    "for folder in patients:\n",
    "    imagelist = os.listdir('data/raw_data/{}/1'.format(folder))\n",
    "    for image in imagelist:\n",
    "        shutil.copyfile('data/raw_data/{}/1/{}'.format(folder, image), 'data/1/{}'.format(image))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING DATA\n",
    "\n",
    "Let's first try our hand on some training data before we jump straight into the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Create the dataframe.\\nimport cv2\\n\\nfile_list = []\\nclass_list = []\\n\\nDATADIR = \"data/sample\"\\n\\n# All the categories you want your neural network to detect\\nCATEGORIES = [\"0\", \"1\"]\\n\\n# The size of the images that your neural network will use\\nIMG_SIZE = 50\\n\\n# Checking for all images in the data folder\\n# Let\\'s use black and white for the images to save on computing power.\\nfor category in CATEGORIES:\\n    path = os.path.join(DATADIR, category)\\n    for img in os.listdir(path):\\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\\n\\nsample_training_data = []\\n\\ndef create_sample_training_data():\\n    for category in CATEGORIES :\\n        path = os.path.join(DATADIR, category)\\n        class_num = CATEGORIES.index(category)\\n        for img in os.listdir(path):\\n            try :\\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\\n                sample_training_data.append([new_array, class_num])\\n            except Exception as e:\\n                pass\\n\\ncreate_sample_training_data()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Create the dataframe.\n",
    "import cv2\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"data/sample\"\n",
    "\n",
    "# All the categories you want your neural network to detect\n",
    "CATEGORIES = [\"0\", \"1\"]\n",
    "\n",
    "# The size of the images that your neural network will use\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Checking for all images in the data folder\n",
    "# Let's use black and white for the images to save on computing power.\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sample_training_data = []\n",
    "\n",
    "def create_sample_training_data():\n",
    "    for category in CATEGORIES :\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try :\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                sample_training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_sample_training_data()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make sure the array still represents the images.\n",
    "#cv2.imshow('image', sample_training_data[0][0])\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample = pd.DataFrame(sample_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\nrandom.shuffle(sample_training_data)\\n\\nX_sample = [] #features\\ny_sample = [] #labels\\n\\nfor features, label in sample_training_data:\\n    X_sample.append(features)\\n    y_sample.append(label)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import random\n",
    "random.shuffle(sample_training_data)\n",
    "\n",
    "X_sample = [] #features\n",
    "y_sample = [] #labels\n",
    "\n",
    "for features, label in sample_training_data:\n",
    "    X_sample.append(features)\n",
    "    y_sample.append(label)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_sample = np.array(X_sample).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\\ny_sample = np.array(y_sample).reshape(-1)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_sample = np.array(X_sample).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_sample = np.array(y_sample).reshape(-1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(X_sample.shape)\\nprint(y_sample.shape)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(X_sample.shape)\n",
    "print(y_sample.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Normalize:\\nX_sample = X_sample/255\\n\\n#Build the model.\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(32, (3, 3), input_shape = X_sample.shape[1:]))\\nmodel.add(Activation(\\'relu\\'))\\nmodel.add(MaxPooling2D(pool_size=(2,2)))\\n\\nmodel.add(Conv2D(64, (3, 3)))\\nmodel.add(Activation(\"relu\"))\\nmodel.add(MaxPooling2D(pool_size=(2,2)))\\n\\nmodel.add(Conv2D(64, (3, 3)))\\nmodel.add(Activation(\"relu\"))\\nmodel.add(MaxPooling2D(pool_size=(2,2)))\\nmodel.add(Dropout(0.25))\\n\\n# 2 hidden layers\\nmodel.add(Flatten())\\nmodel.add(Dense(128))\\nmodel.add(Activation(\"relu\"))\\n\\nmodel.add(Dense(128))\\nmodel.add(Activation(\"relu\"))\\n\\n# The output layer with 2 neurons, for 2 classes\\nmodel.add(Dense(2))\\nmodel.add(Activation(\"softmax\"))'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Normalize:\n",
    "X_sample = X_sample/255\n",
    "\n",
    "#Build the model.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X_sample.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# The output layer with 2 neurons, for 2 classes\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Time to fit the model.\\nsample_fit = model.fit(X_sample, y_sample, batch_size=32, epochs=100, validation_split=0.1)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Time to fit the model.\n",
    "sample_fit = model.fit(X_sample, y_sample, batch_size=32, epochs=100, validation_split=0.1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(sample_fit.history.keys())\\nplt.figure(1)\\nplt.plot(sample_fit.history['acc'])\\nplt.plot(sample_fit.history['val_acc'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'validation'], loc='upper left')\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(sample_fit.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(sample_fit.history['acc'])\n",
    "plt.plot(sample_fit.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good from here. I'm not going to worry about the accuracy since the data it was trained on was so small. \n",
    "\n",
    "On to the real data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframe.\n",
    "import cv2\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "# All the categories you want your neural network to detect\n",
    "CATEGORIES = [\"0\", \"1\"]\n",
    "\n",
    "# The size of the images that your neural network will use\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Checking for all images in the data folder\n",
    "# Let's use black and white for the images to save on computing power.\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES :\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try :\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277524, 50, 50, 1)\n",
      "(277524,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y).reshape(-1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 16:44:35.575602 140696779343680 deprecation.py:506] From /home/paperspace/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Normalize:\n",
    "X = X/255\n",
    "\n",
    "#Build the model.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# The output layer with 2 neurons, for 2 classes\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249771 samples, validate on 27753 samples\n",
      "Epoch 1/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.4611 - acc: 0.7877 - val_loss: 0.4434 - val_acc: 0.7999\n",
      "Epoch 2/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4288 - acc: 0.8086 - val_loss: 0.4144 - val_acc: 0.8148\n",
      "Epoch 3/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.4177 - acc: 0.8141 - val_loss: 0.4049 - val_acc: 0.8190\n",
      "Epoch 4/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4105 - acc: 0.8181 - val_loss: 0.4319 - val_acc: 0.8032\n",
      "Epoch 5/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4034 - acc: 0.8214 - val_loss: 0.3985 - val_acc: 0.8222\n",
      "Epoch 6/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3984 - acc: 0.8238 - val_loss: 0.4008 - val_acc: 0.8221\n",
      "Epoch 7/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3930 - acc: 0.8268 - val_loss: 0.4030 - val_acc: 0.8190\n",
      "Epoch 8/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3889 - acc: 0.8289 - val_loss: 0.3917 - val_acc: 0.8284\n",
      "Epoch 9/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3857 - acc: 0.8304 - val_loss: 0.3851 - val_acc: 0.8309\n",
      "Epoch 10/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3835 - acc: 0.8319 - val_loss: 0.3879 - val_acc: 0.8289\n",
      "Epoch 11/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3802 - acc: 0.8338 - val_loss: 0.3852 - val_acc: 0.8319\n",
      "Epoch 12/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3777 - acc: 0.8349 - val_loss: 0.3848 - val_acc: 0.8311\n",
      "Epoch 13/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3761 - acc: 0.8352 - val_loss: 0.3838 - val_acc: 0.8294\n",
      "Epoch 14/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3733 - acc: 0.8366 - val_loss: 0.3825 - val_acc: 0.8297\n",
      "Epoch 15/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3711 - acc: 0.8381 - val_loss: 0.3795 - val_acc: 0.8322\n",
      "Epoch 16/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3694 - acc: 0.8387 - val_loss: 0.3759 - val_acc: 0.8358\n",
      "Epoch 17/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3685 - acc: 0.8394 - val_loss: 0.3793 - val_acc: 0.8323\n",
      "Epoch 18/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3671 - acc: 0.8408 - val_loss: 0.3781 - val_acc: 0.8312\n",
      "Epoch 19/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3647 - acc: 0.8412 - val_loss: 0.3777 - val_acc: 0.8340\n",
      "Epoch 20/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3639 - acc: 0.8420 - val_loss: 0.3730 - val_acc: 0.8352\n",
      "Epoch 21/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3628 - acc: 0.8416 - val_loss: 0.3886 - val_acc: 0.8297\n",
      "Epoch 22/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3626 - acc: 0.8421 - val_loss: 0.3809 - val_acc: 0.8319\n",
      "Epoch 23/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3597 - acc: 0.8441 - val_loss: 0.3791 - val_acc: 0.8318\n",
      "Epoch 24/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3584 - acc: 0.8451 - val_loss: 0.3733 - val_acc: 0.8334\n",
      "Epoch 25/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3576 - acc: 0.8453 - val_loss: 0.3837 - val_acc: 0.8319\n",
      "Epoch 26/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3555 - acc: 0.8462 - val_loss: 0.3752 - val_acc: 0.8355\n",
      "Epoch 27/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3538 - acc: 0.8477 - val_loss: 0.3789 - val_acc: 0.8333\n",
      "Epoch 28/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3539 - acc: 0.8469 - val_loss: 0.3723 - val_acc: 0.8361\n",
      "Epoch 29/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.3526 - acc: 0.8473 - val_loss: 0.3737 - val_acc: 0.8342\n",
      "Epoch 30/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3501 - acc: 0.8488 - val_loss: 0.3738 - val_acc: 0.8347\n",
      "Epoch 31/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.3484 - acc: 0.8500 - val_loss: 0.3853 - val_acc: 0.8314\n",
      "Epoch 32/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3525 - acc: 0.8494 - val_loss: 0.3768 - val_acc: 0.8336\n",
      "Epoch 33/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3471 - acc: 0.8504 - val_loss: 0.3768 - val_acc: 0.8344\n",
      "Epoch 34/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3523 - acc: 0.8488 - val_loss: 0.3767 - val_acc: 0.8349\n",
      "Epoch 35/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3505 - acc: 0.8496 - val_loss: 0.3759 - val_acc: 0.8369\n",
      "Epoch 36/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3435 - acc: 0.8528 - val_loss: 0.3761 - val_acc: 0.8373\n",
      "Epoch 37/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3430 - acc: 0.8528 - val_loss: 0.3712 - val_acc: 0.8368\n",
      "Epoch 38/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3425 - acc: 0.8535 - val_loss: 0.3756 - val_acc: 0.8353\n",
      "Epoch 39/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3459 - acc: 0.8519 - val_loss: 0.3861 - val_acc: 0.8320\n",
      "Epoch 40/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3414 - acc: 0.8535 - val_loss: 0.3794 - val_acc: 0.8332\n",
      "Epoch 41/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3397 - acc: 0.8551 - val_loss: 0.3734 - val_acc: 0.8361\n",
      "Epoch 42/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3392 - acc: 0.8550 - val_loss: 0.3749 - val_acc: 0.8363\n",
      "Epoch 43/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3380 - acc: 0.8549 - val_loss: 0.3765 - val_acc: 0.8371\n",
      "Epoch 44/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.3376 - acc: 0.8560 - val_loss: 0.3711 - val_acc: 0.8362\n",
      "Epoch 45/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.3865 - acc: 0.8369 - val_loss: 0.3748 - val_acc: 0.8376\n",
      "Epoch 46/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3369 - acc: 0.8564 - val_loss: 0.3732 - val_acc: 0.8372\n",
      "Epoch 47/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3358 - acc: 0.8564 - val_loss: 0.3771 - val_acc: 0.8358\n",
      "Epoch 48/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3356 - acc: 0.8569 - val_loss: 0.3793 - val_acc: 0.8344\n",
      "Epoch 49/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3330 - acc: 0.8578 - val_loss: 0.3742 - val_acc: 0.8331\n",
      "Epoch 50/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3343 - acc: 0.8583 - val_loss: 0.3713 - val_acc: 0.8360\n",
      "Epoch 51/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3314 - acc: 0.8587 - val_loss: 0.3859 - val_acc: 0.8345\n",
      "Epoch 52/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3315 - acc: 0.8588 - val_loss: 0.3821 - val_acc: 0.8345\n",
      "Epoch 53/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3312 - acc: 0.8586 - val_loss: 0.3895 - val_acc: 0.8291\n",
      "Epoch 54/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3602 - acc: 0.8449 - val_loss: 0.4275 - val_acc: 0.8063\n",
      "Epoch 55/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3479 - acc: 0.8511 - val_loss: 0.3735 - val_acc: 0.8359\n",
      "Epoch 56/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3400 - acc: 0.8546 - val_loss: 0.3749 - val_acc: 0.8349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3303 - acc: 0.8591 - val_loss: 0.3786 - val_acc: 0.8335\n",
      "Epoch 58/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3310 - acc: 0.8589 - val_loss: 0.3777 - val_acc: 0.8342\n",
      "Epoch 59/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3281 - acc: 0.8610 - val_loss: 0.3785 - val_acc: 0.8331\n",
      "Epoch 60/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3280 - acc: 0.8606 - val_loss: 0.3755 - val_acc: 0.8339\n",
      "Epoch 61/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3268 - acc: 0.8611 - val_loss: 0.3844 - val_acc: 0.8351\n",
      "Epoch 62/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3270 - acc: 0.8604 - val_loss: 0.3902 - val_acc: 0.8315\n",
      "Epoch 63/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3273 - acc: 0.8617 - val_loss: 0.3837 - val_acc: 0.8348\n",
      "Epoch 64/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3246 - acc: 0.8620 - val_loss: 0.4192 - val_acc: 0.8143\n",
      "Epoch 65/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3650 - acc: 0.8450 - val_loss: 0.4190 - val_acc: 0.8187\n",
      "Epoch 66/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3366 - acc: 0.8560 - val_loss: 0.3851 - val_acc: 0.8337\n",
      "Epoch 67/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3242 - acc: 0.8626 - val_loss: 0.3886 - val_acc: 0.8336\n",
      "Epoch 68/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3241 - acc: 0.8623 - val_loss: 0.4045 - val_acc: 0.8290\n",
      "Epoch 69/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3227 - acc: 0.8634 - val_loss: 0.3924 - val_acc: 0.8325\n",
      "Epoch 70/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3233 - acc: 0.8628 - val_loss: 0.3926 - val_acc: 0.8310\n",
      "Epoch 71/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3216 - acc: 0.8635 - val_loss: 0.3853 - val_acc: 0.8321\n",
      "Epoch 72/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3499 - acc: 0.8496 - val_loss: 0.3827 - val_acc: 0.8313\n",
      "Epoch 73/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3232 - acc: 0.8636 - val_loss: 0.3766 - val_acc: 0.8357\n",
      "Epoch 74/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3399 - acc: 0.8532 - val_loss: 0.3834 - val_acc: 0.8342\n",
      "Epoch 75/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3214 - acc: 0.8647 - val_loss: 0.3905 - val_acc: 0.8309\n",
      "Epoch 76/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3210 - acc: 0.8641 - val_loss: 0.3906 - val_acc: 0.8304\n",
      "Epoch 77/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3217 - acc: 0.8635 - val_loss: 0.3842 - val_acc: 0.8352\n",
      "Epoch 78/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3192 - acc: 0.8646 - val_loss: 0.3891 - val_acc: 0.8296\n",
      "Epoch 79/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3198 - acc: 0.8645 - val_loss: 0.3866 - val_acc: 0.8328\n",
      "Epoch 80/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3199 - acc: 0.8652 - val_loss: 0.4049 - val_acc: 0.8352\n",
      "Epoch 81/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3297 - acc: 0.8601 - val_loss: 0.4038 - val_acc: 0.8200\n",
      "Epoch 82/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3250 - acc: 0.8621 - val_loss: 0.3812 - val_acc: 0.8321\n",
      "Epoch 83/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3239 - acc: 0.8627 - val_loss: 0.3822 - val_acc: 0.8351\n",
      "Epoch 84/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3209 - acc: 0.8644 - val_loss: 0.3894 - val_acc: 0.8304\n",
      "Epoch 85/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3215 - acc: 0.8646 - val_loss: 0.3832 - val_acc: 0.8304\n",
      "Epoch 86/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3170 - acc: 0.8657 - val_loss: 0.4120 - val_acc: 0.8325\n",
      "Epoch 87/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3259 - acc: 0.8616 - val_loss: 0.3826 - val_acc: 0.8338\n",
      "Epoch 88/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3202 - acc: 0.8651 - val_loss: 0.3875 - val_acc: 0.8290\n",
      "Epoch 89/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3324 - acc: 0.8580 - val_loss: 0.4049 - val_acc: 0.8243\n",
      "Epoch 90/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3192 - acc: 0.8652 - val_loss: 0.3804 - val_acc: 0.8329\n",
      "Epoch 91/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3161 - acc: 0.8666 - val_loss: 0.3925 - val_acc: 0.8325\n",
      "Epoch 92/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3156 - acc: 0.8673 - val_loss: 0.4044 - val_acc: 0.8280\n",
      "Epoch 93/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3258 - acc: 0.8633 - val_loss: 0.4535 - val_acc: 0.7887\n",
      "Epoch 94/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.3334 - acc: 0.8566 - val_loss: 0.4115 - val_acc: 0.8341\n",
      "Epoch 95/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3196 - acc: 0.8648 - val_loss: 0.3980 - val_acc: 0.8293\n",
      "Epoch 96/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3182 - acc: 0.8655 - val_loss: 0.3904 - val_acc: 0.8341\n",
      "Epoch 97/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3196 - acc: 0.8650 - val_loss: 0.3825 - val_acc: 0.8306\n",
      "Epoch 98/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3167 - acc: 0.8662 - val_loss: 0.3926 - val_acc: 0.8331\n",
      "Epoch 99/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5881 - acc: 0.8281 - val_loss: 0.4009 - val_acc: 0.8230\n",
      "Epoch 100/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3350 - acc: 0.8585 - val_loss: 0.3811 - val_acc: 0.8375\n",
      "Epoch 101/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3188 - acc: 0.8654 - val_loss: 0.3867 - val_acc: 0.8309\n",
      "Epoch 102/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3145 - acc: 0.8674 - val_loss: 0.4571 - val_acc: 0.8243\n",
      "Epoch 103/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3144 - acc: 0.8673 - val_loss: 0.4034 - val_acc: 0.8313\n",
      "Epoch 104/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3142 - acc: 0.8675 - val_loss: 0.3931 - val_acc: 0.8327\n",
      "Epoch 105/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3147 - acc: 0.8673 - val_loss: 0.4096 - val_acc: 0.8308\n",
      "Epoch 106/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3162 - acc: 0.8667 - val_loss: 0.4107 - val_acc: 0.8343\n",
      "Epoch 107/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3128 - acc: 0.8679 - val_loss: 0.3944 - val_acc: 0.8264\n",
      "Epoch 108/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3224 - acc: 0.8634 - val_loss: 0.3877 - val_acc: 0.8337\n",
      "Epoch 109/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3182 - acc: 0.8661 - val_loss: 0.3849 - val_acc: 0.8314\n",
      "Epoch 110/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3135 - acc: 0.8677 - val_loss: 0.4119 - val_acc: 0.8329\n",
      "Epoch 111/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3139 - acc: 0.8676 - val_loss: 0.3907 - val_acc: 0.8293\n",
      "Epoch 112/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3125 - acc: 0.8676 - val_loss: 0.4045 - val_acc: 0.8281\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3132 - acc: 0.8688 - val_loss: 0.3828 - val_acc: 0.8346\n",
      "Epoch 114/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3139 - acc: 0.8679 - val_loss: 0.3916 - val_acc: 0.8298\n",
      "Epoch 115/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3138 - acc: 0.8681 - val_loss: 0.4068 - val_acc: 0.8289\n",
      "Epoch 116/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3114 - acc: 0.8689 - val_loss: 0.3908 - val_acc: 0.8318\n",
      "Epoch 117/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3121 - acc: 0.8684 - val_loss: 0.5618 - val_acc: 0.8311\n",
      "Epoch 118/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3231 - acc: 0.8623 - val_loss: 0.3891 - val_acc: 0.8335\n",
      "Epoch 119/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3236 - acc: 0.8633 - val_loss: 0.3909 - val_acc: 0.8343\n",
      "Epoch 120/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3128 - acc: 0.8679 - val_loss: 0.3995 - val_acc: 0.8313\n",
      "Epoch 121/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3124 - acc: 0.8685 - val_loss: 0.3869 - val_acc: 0.8332\n",
      "Epoch 122/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4053 - acc: 0.8354 - val_loss: 0.3938 - val_acc: 0.8219\n",
      "Epoch 123/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 2.1924 - acc: 0.8078 - val_loss: 0.4170 - val_acc: 0.8177\n",
      "Epoch 124/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3725 - acc: 0.8384 - val_loss: 0.3979 - val_acc: 0.8334\n",
      "Epoch 125/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3220 - acc: 0.8642 - val_loss: 0.3865 - val_acc: 0.8337\n",
      "Epoch 126/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3147 - acc: 0.8668 - val_loss: 0.4257 - val_acc: 0.8297\n",
      "Epoch 127/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3143 - acc: 0.8676 - val_loss: 0.3881 - val_acc: 0.8343\n",
      "Epoch 128/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3133 - acc: 0.8686 - val_loss: 0.3964 - val_acc: 0.8297\n",
      "Epoch 129/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3138 - acc: 0.8685 - val_loss: 0.3908 - val_acc: 0.8329\n",
      "Epoch 130/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3177 - acc: 0.8663 - val_loss: 0.3812 - val_acc: 0.8334\n",
      "Epoch 131/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3267 - acc: 0.8619 - val_loss: 0.3909 - val_acc: 0.8320\n",
      "Epoch 132/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3159 - acc: 0.8676 - val_loss: 0.4199 - val_acc: 0.8323\n",
      "Epoch 133/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3099 - acc: 0.8695 - val_loss: 0.4173 - val_acc: 0.8289\n",
      "Epoch 134/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3089 - acc: 0.8701 - val_loss: 0.4360 - val_acc: 0.8298\n",
      "Epoch 135/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3534 - acc: 0.8527 - val_loss: 0.3927 - val_acc: 0.8336\n",
      "Epoch 136/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3133 - acc: 0.8680 - val_loss: 0.4366 - val_acc: 0.8321\n",
      "Epoch 137/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4391 - acc: 0.8513 - val_loss: 0.4039 - val_acc: 0.8257\n",
      "Epoch 138/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3248 - acc: 0.8632 - val_loss: 0.3908 - val_acc: 0.8334\n",
      "Epoch 139/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3108 - acc: 0.8694 - val_loss: 0.3936 - val_acc: 0.8330\n",
      "Epoch 140/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3124 - acc: 0.8681 - val_loss: 0.4000 - val_acc: 0.8334\n",
      "Epoch 141/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3114 - acc: 0.8690 - val_loss: 0.3887 - val_acc: 0.8301\n",
      "Epoch 142/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4266 - acc: 0.8398 - val_loss: 0.3979 - val_acc: 0.8345\n",
      "Epoch 143/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3159 - acc: 0.8681 - val_loss: 0.3877 - val_acc: 0.8304\n",
      "Epoch 144/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3102 - acc: 0.8698 - val_loss: 0.4097 - val_acc: 0.8286\n",
      "Epoch 145/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3221 - acc: 0.8666 - val_loss: 0.4886 - val_acc: 0.7120\n",
      "Epoch 146/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3410 - acc: 0.8539 - val_loss: 0.3895 - val_acc: 0.8314\n",
      "Epoch 147/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3163 - acc: 0.8676 - val_loss: 0.3869 - val_acc: 0.8321\n",
      "Epoch 148/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3106 - acc: 0.8699 - val_loss: 0.4171 - val_acc: 0.8294\n",
      "Epoch 149/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3225 - acc: 0.8636 - val_loss: 0.4017 - val_acc: 0.8308\n",
      "Epoch 150/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3097 - acc: 0.8704 - val_loss: 0.3865 - val_acc: 0.8328\n",
      "Epoch 151/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3088 - acc: 0.8710 - val_loss: 0.6389 - val_acc: 0.7624\n",
      "Epoch 152/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3271 - acc: 0.8617 - val_loss: 0.3946 - val_acc: 0.8264\n",
      "Epoch 153/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3163 - acc: 0.8664 - val_loss: 0.3897 - val_acc: 0.8332\n",
      "Epoch 154/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3078 - acc: 0.8715 - val_loss: 0.4862 - val_acc: 0.8278\n",
      "Epoch 155/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3089 - acc: 0.8706 - val_loss: 0.3919 - val_acc: 0.8256\n",
      "Epoch 156/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3096 - acc: 0.8705 - val_loss: 0.3842 - val_acc: 0.8310\n",
      "Epoch 157/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3116 - acc: 0.8696 - val_loss: 0.4200 - val_acc: 0.8263\n",
      "Epoch 158/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.3130 - acc: 0.8690 - val_loss: 0.3949 - val_acc: 0.8326\n",
      "Epoch 159/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3151 - acc: 0.8684 - val_loss: 0.3924 - val_acc: 0.8302\n",
      "Epoch 160/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3104 - acc: 0.8701 - val_loss: 0.3954 - val_acc: 0.8307\n",
      "Epoch 161/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3178 - acc: 0.8689 - val_loss: 0.4418 - val_acc: 0.8302\n",
      "Epoch 162/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3301 - acc: 0.8622 - val_loss: 0.4069 - val_acc: 0.8319\n",
      "Epoch 163/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3104 - acc: 0.8703 - val_loss: 0.4221 - val_acc: 0.8065\n",
      "Epoch 164/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3155 - acc: 0.8676 - val_loss: 0.4716 - val_acc: 0.8269\n",
      "Epoch 165/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3100 - acc: 0.8697 - val_loss: 0.4742 - val_acc: 0.8291\n",
      "Epoch 166/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3116 - acc: 0.8693 - val_loss: 0.9376 - val_acc: 0.8326\n",
      "Epoch 167/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3118 - acc: 0.8695 - val_loss: 0.4817 - val_acc: 0.8262\n",
      "Epoch 168/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3119 - acc: 0.8696 - val_loss: 0.4418 - val_acc: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3316 - acc: 0.8611 - val_loss: 0.3918 - val_acc: 0.8318\n",
      "Epoch 170/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3088 - acc: 0.8700 - val_loss: 0.4269 - val_acc: 0.8280\n",
      "Epoch 171/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3092 - acc: 0.8702 - val_loss: 0.8885 - val_acc: 0.8311\n",
      "Epoch 172/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3852 - acc: 0.8530 - val_loss: 0.4001 - val_acc: 0.8217\n",
      "Epoch 173/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3433 - acc: 0.8531 - val_loss: 0.4799 - val_acc: 0.8288\n",
      "Epoch 174/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3092 - acc: 0.8700 - val_loss: 0.4988 - val_acc: 0.8306\n",
      "Epoch 175/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3075 - acc: 0.8717 - val_loss: 0.3956 - val_acc: 0.8283\n",
      "Epoch 176/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3093 - acc: 0.8708 - val_loss: 0.3969 - val_acc: 0.8300\n",
      "Epoch 177/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3328 - acc: 0.8621 - val_loss: 0.3950 - val_acc: 0.8293\n",
      "Epoch 178/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3961 - acc: 0.8580 - val_loss: 0.3915 - val_acc: 0.8295\n",
      "Epoch 179/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3109 - acc: 0.8701 - val_loss: 0.4247 - val_acc: 0.8278\n",
      "Epoch 180/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3063 - acc: 0.8716 - val_loss: 0.3891 - val_acc: 0.8315\n",
      "Epoch 181/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3100 - acc: 0.8703 - val_loss: 0.3931 - val_acc: 0.8312\n",
      "Epoch 182/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3144 - acc: 0.8673 - val_loss: 0.3988 - val_acc: 0.8262\n",
      "Epoch 183/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3146 - acc: 0.8681 - val_loss: 0.4079 - val_acc: 0.8291\n",
      "Epoch 184/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3123 - acc: 0.8697 - val_loss: 0.6495 - val_acc: 0.8312\n",
      "Epoch 185/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3096 - acc: 0.8712 - val_loss: 0.4000 - val_acc: 0.8328\n",
      "Epoch 186/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3086 - acc: 0.8711 - val_loss: 0.4477 - val_acc: 0.8298\n",
      "Epoch 187/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.5101 - acc: 0.8271 - val_loss: 0.3885 - val_acc: 0.8343\n",
      "Epoch 188/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3287 - acc: 0.8615 - val_loss: 0.4200 - val_acc: 0.8293\n",
      "Epoch 189/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3085 - acc: 0.8709 - val_loss: 0.4174 - val_acc: 0.8297\n",
      "Epoch 190/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3093 - acc: 0.8701 - val_loss: 0.5819 - val_acc: 0.8329\n",
      "Epoch 191/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3084 - acc: 0.8707 - val_loss: 0.4302 - val_acc: 0.8305\n",
      "Epoch 192/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3070 - acc: 0.8718 - val_loss: 0.5103 - val_acc: 0.8269\n",
      "Epoch 193/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3079 - acc: 0.8712 - val_loss: 0.4612 - val_acc: 0.8293\n",
      "Epoch 194/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3059 - acc: 0.8723 - val_loss: 0.5376 - val_acc: 0.8296\n",
      "Epoch 195/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3088 - acc: 0.8715 - val_loss: 0.3890 - val_acc: 0.8297\n",
      "Epoch 196/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3119 - acc: 0.8691 - val_loss: 0.5861 - val_acc: 0.8290\n",
      "Epoch 197/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3280 - acc: 0.8614 - val_loss: 0.4339 - val_acc: 0.8323\n",
      "Epoch 198/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3260 - acc: 0.8647 - val_loss: 0.4217 - val_acc: 0.8314\n",
      "Epoch 199/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3208 - acc: 0.8657 - val_loss: 0.3944 - val_acc: 0.8330\n",
      "Epoch 200/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3403 - acc: 0.8559 - val_loss: 0.4016 - val_acc: 0.8293\n",
      "Epoch 201/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3447 - acc: 0.8553 - val_loss: 0.3897 - val_acc: 0.8308\n",
      "Epoch 202/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3170 - acc: 0.8665 - val_loss: 0.4095 - val_acc: 0.8317\n",
      "Epoch 203/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.3174 - acc: 0.8661 - val_loss: 0.4219 - val_acc: 0.8249\n",
      "Epoch 204/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3138 - acc: 0.8687 - val_loss: 0.4587 - val_acc: 0.7917\n",
      "Epoch 205/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3164 - acc: 0.8664 - val_loss: 1.2755 - val_acc: 0.8306\n",
      "Epoch 206/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3082 - acc: 0.8713 - val_loss: 0.5927 - val_acc: 0.8314\n",
      "Epoch 207/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3732 - acc: 0.8556 - val_loss: 0.3828 - val_acc: 0.8304\n",
      "Epoch 208/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3179 - acc: 0.8665 - val_loss: 0.4870 - val_acc: 0.8294\n",
      "Epoch 209/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3075 - acc: 0.8714 - val_loss: 0.4179 - val_acc: 0.8305\n",
      "Epoch 210/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3222 - acc: 0.8648 - val_loss: 0.4056 - val_acc: 0.8306\n",
      "Epoch 211/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3603 - acc: 0.8449 - val_loss: 0.4120 - val_acc: 0.8190\n",
      "Epoch 212/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3410 - acc: 0.8561 - val_loss: 0.3974 - val_acc: 0.8291\n",
      "Epoch 213/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3106 - acc: 0.8707 - val_loss: 0.4738 - val_acc: 0.8292\n",
      "Epoch 214/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3689 - acc: 0.8423 - val_loss: 0.3987 - val_acc: 0.8289\n",
      "Epoch 215/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.4633 - acc: 0.8182 - val_loss: 0.4010 - val_acc: 0.8318\n",
      "Epoch 216/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3220 - acc: 0.8641 - val_loss: 0.3896 - val_acc: 0.8299\n",
      "Epoch 217/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4659 - acc: 0.8347 - val_loss: 0.4103 - val_acc: 0.8183\n",
      "Epoch 218/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3392 - acc: 0.8554 - val_loss: 0.5630 - val_acc: 0.8336\n",
      "Epoch 219/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4734 - acc: 0.8457 - val_loss: 0.4126 - val_acc: 0.8154\n",
      "Epoch 220/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3354 - acc: 0.8600 - val_loss: 0.4058 - val_acc: 0.8219\n",
      "Epoch 221/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3150 - acc: 0.8679 - val_loss: 1.2864 - val_acc: 0.8333\n",
      "Epoch 222/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3191 - acc: 0.8675 - val_loss: 0.4296 - val_acc: 0.8330\n",
      "Epoch 223/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3130 - acc: 0.8692 - val_loss: 1.1858 - val_acc: 0.8333\n",
      "Epoch 224/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3206 - acc: 0.8659 - val_loss: 0.3959 - val_acc: 0.8338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3546 - acc: 0.8540 - val_loss: 0.3934 - val_acc: 0.8309\n",
      "Epoch 226/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3133 - acc: 0.8693 - val_loss: 0.4386 - val_acc: 0.8327\n",
      "Epoch 227/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3099 - acc: 0.8697 - val_loss: 0.5185 - val_acc: 0.8269\n",
      "Epoch 228/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.4988 - acc: 0.8580 - val_loss: 0.3977 - val_acc: 0.8277\n",
      "Epoch 229/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3689 - acc: 0.8504 - val_loss: 0.3945 - val_acc: 0.8335\n",
      "Epoch 230/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3176 - acc: 0.8671 - val_loss: 0.3936 - val_acc: 0.8332\n",
      "Epoch 231/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3118 - acc: 0.8696 - val_loss: 0.6378 - val_acc: 0.7963\n",
      "Epoch 232/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3177 - acc: 0.8680 - val_loss: 0.4594 - val_acc: 0.8275\n",
      "Epoch 233/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3217 - acc: 0.8657 - val_loss: 0.4002 - val_acc: 0.8318\n",
      "Epoch 234/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3400 - acc: 0.8635 - val_loss: 2.0597 - val_acc: 0.8016\n",
      "Epoch 235/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3478 - acc: 0.8575 - val_loss: 0.4185 - val_acc: 0.8320\n",
      "Epoch 236/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3112 - acc: 0.8708 - val_loss: 2.1648 - val_acc: 0.8322\n",
      "Epoch 237/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3213 - acc: 0.8663 - val_loss: 0.4190 - val_acc: 0.8334\n",
      "Epoch 238/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3237 - acc: 0.8663 - val_loss: 0.3965 - val_acc: 0.8236\n",
      "Epoch 239/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3241 - acc: 0.8637 - val_loss: 0.4095 - val_acc: 0.8323\n",
      "Epoch 240/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3142 - acc: 0.8688 - val_loss: 0.3827 - val_acc: 0.8353\n",
      "Epoch 241/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3201 - acc: 0.8667 - val_loss: 0.3904 - val_acc: 0.8315\n",
      "Epoch 242/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3146 - acc: 0.8680 - val_loss: 0.3860 - val_acc: 0.8323\n",
      "Epoch 243/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3129 - acc: 0.8694 - val_loss: 0.3962 - val_acc: 0.8361\n",
      "Epoch 244/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3109 - acc: 0.8706 - val_loss: 0.4310 - val_acc: 0.8317\n",
      "Epoch 245/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3320 - acc: 0.8606 - val_loss: 0.4016 - val_acc: 0.8351\n",
      "Epoch 246/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3100 - acc: 0.8706 - val_loss: 0.5677 - val_acc: 0.8353\n",
      "Epoch 247/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3095 - acc: 0.8707 - val_loss: 0.4150 - val_acc: 0.8282\n",
      "Epoch 248/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3124 - acc: 0.8696 - val_loss: 0.4050 - val_acc: 0.8342\n",
      "Epoch 249/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3292 - acc: 0.8616 - val_loss: 0.3918 - val_acc: 0.8303\n",
      "Epoch 250/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3399 - acc: 0.8567 - val_loss: 0.4109 - val_acc: 0.8278\n",
      "Epoch 251/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3104 - acc: 0.8705 - val_loss: 0.4061 - val_acc: 0.8327\n",
      "Epoch 252/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3442 - acc: 0.8558 - val_loss: 0.4091 - val_acc: 0.8256\n",
      "Epoch 253/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3172 - acc: 0.8666 - val_loss: 1.3610 - val_acc: 0.8336\n",
      "Epoch 254/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3141 - acc: 0.8692 - val_loss: 0.4071 - val_acc: 0.8292\n",
      "Epoch 255/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3118 - acc: 0.8696 - val_loss: 0.4012 - val_acc: 0.8336\n",
      "Epoch 256/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3110 - acc: 0.8705 - val_loss: 0.4064 - val_acc: 0.8286\n",
      "Epoch 257/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3441 - acc: 0.8520 - val_loss: 0.4153 - val_acc: 0.8341\n",
      "Epoch 258/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3132 - acc: 0.8699 - val_loss: 0.4266 - val_acc: 0.8321\n",
      "Epoch 259/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3133 - acc: 0.8685 - val_loss: 0.4112 - val_acc: 0.8297\n",
      "Epoch 260/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3494 - acc: 0.8672 - val_loss: 0.3996 - val_acc: 0.8328\n",
      "Epoch 261/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3068 - acc: 0.8713 - val_loss: 0.4989 - val_acc: 0.8329\n",
      "Epoch 262/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3097 - acc: 0.8707 - val_loss: 0.4612 - val_acc: 0.8335\n",
      "Epoch 263/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3122 - acc: 0.8705 - val_loss: 0.4100 - val_acc: 0.8291\n",
      "Epoch 264/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5582 - acc: 0.8561 - val_loss: 0.4587 - val_acc: 0.7992\n",
      "Epoch 265/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4415 - acc: 0.8108 - val_loss: 0.3989 - val_acc: 0.8259\n",
      "Epoch 266/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4319 - acc: 0.8520 - val_loss: 0.3961 - val_acc: 0.8300\n",
      "Epoch 267/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3358 - acc: 0.8606 - val_loss: 0.4116 - val_acc: 0.8205\n",
      "Epoch 268/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3395 - acc: 0.8616 - val_loss: 0.3814 - val_acc: 0.8321\n",
      "Epoch 269/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3334 - acc: 0.8608 - val_loss: 0.3960 - val_acc: 0.8297\n",
      "Epoch 270/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3433 - acc: 0.8572 - val_loss: 0.3863 - val_acc: 0.8300\n",
      "Epoch 271/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3186 - acc: 0.8678 - val_loss: 0.3981 - val_acc: 0.8276\n",
      "Epoch 272/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3915 - acc: 0.8411 - val_loss: 0.4225 - val_acc: 0.8089\n",
      "Epoch 273/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.5005 - acc: 0.8145 - val_loss: 0.4086 - val_acc: 0.8188\n",
      "Epoch 274/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3850 - acc: 0.8358 - val_loss: 0.4207 - val_acc: 0.8122\n",
      "Epoch 275/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3507 - acc: 0.8531 - val_loss: 0.3863 - val_acc: 0.8346\n",
      "Epoch 276/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.4136 - acc: 0.8482 - val_loss: 0.3982 - val_acc: 0.8250\n",
      "Epoch 277/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3843 - acc: 0.8468 - val_loss: 0.3802 - val_acc: 0.8330\n",
      "Epoch 278/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3344 - acc: 0.8604 - val_loss: 0.3874 - val_acc: 0.8309\n",
      "Epoch 279/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3450 - acc: 0.8559 - val_loss: 0.3851 - val_acc: 0.8324\n",
      "Epoch 280/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3471 - acc: 0.8589 - val_loss: 0.3828 - val_acc: 0.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3448 - acc: 0.8594 - val_loss: 0.3797 - val_acc: 0.8384\n",
      "Epoch 282/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3511 - acc: 0.8511 - val_loss: 0.3894 - val_acc: 0.8287\n",
      "Epoch 283/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3262 - acc: 0.8641 - val_loss: 0.5506 - val_acc: 0.8331\n",
      "Epoch 284/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3764 - acc: 0.8513 - val_loss: 0.3997 - val_acc: 0.8269\n",
      "Epoch 285/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3805 - acc: 0.8373 - val_loss: 0.3910 - val_acc: 0.8300\n",
      "Epoch 286/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3484 - acc: 0.8542 - val_loss: 0.4474 - val_acc: 0.7939\n",
      "Epoch 287/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3481 - acc: 0.8524 - val_loss: 0.3862 - val_acc: 0.8322\n",
      "Epoch 288/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3470 - acc: 0.8576 - val_loss: 0.4083 - val_acc: 0.8199\n",
      "Epoch 289/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3394 - acc: 0.8592 - val_loss: 0.3833 - val_acc: 0.8356\n",
      "Epoch 290/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3257 - acc: 0.8645 - val_loss: 0.4069 - val_acc: 0.8225\n",
      "Epoch 291/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3528 - acc: 0.8505 - val_loss: 0.3950 - val_acc: 0.8226\n",
      "Epoch 292/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4296 - acc: 0.8355 - val_loss: 0.3824 - val_acc: 0.8321\n",
      "Epoch 293/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3366 - acc: 0.8588 - val_loss: 0.4144 - val_acc: 0.8372\n",
      "Epoch 294/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3342 - acc: 0.8602 - val_loss: 0.3859 - val_acc: 0.8343\n",
      "Epoch 295/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3867 - acc: 0.8447 - val_loss: 0.3796 - val_acc: 0.8346\n",
      "Epoch 296/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3452 - acc: 0.8545 - val_loss: 0.3869 - val_acc: 0.8313\n",
      "Epoch 297/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3292 - acc: 0.8627 - val_loss: 0.3787 - val_acc: 0.8320\n",
      "Epoch 298/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3699 - acc: 0.8523 - val_loss: 0.3828 - val_acc: 0.8310\n",
      "Epoch 299/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3288 - acc: 0.8632 - val_loss: 0.3859 - val_acc: 0.8309\n",
      "Epoch 300/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3365 - acc: 0.8590 - val_loss: 0.3921 - val_acc: 0.8302\n",
      "Epoch 301/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3343 - acc: 0.8608 - val_loss: 0.3875 - val_acc: 0.8363\n",
      "Epoch 302/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.4475 - acc: 0.8484 - val_loss: 0.4113 - val_acc: 0.8183\n",
      "Epoch 303/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3803 - acc: 0.8357 - val_loss: 0.4000 - val_acc: 0.8221\n",
      "Epoch 304/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3317 - acc: 0.8617 - val_loss: 0.3845 - val_acc: 0.8308\n",
      "Epoch 305/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3350 - acc: 0.8598 - val_loss: 0.3961 - val_acc: 0.8296\n",
      "Epoch 306/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3377 - acc: 0.8586 - val_loss: 0.4100 - val_acc: 0.8164\n",
      "Epoch 307/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3410 - acc: 0.8575 - val_loss: 0.3934 - val_acc: 0.8302\n",
      "Epoch 308/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3374 - acc: 0.8586 - val_loss: 0.3912 - val_acc: 0.8261\n",
      "Epoch 309/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4264 - acc: 0.8205 - val_loss: 0.3851 - val_acc: 0.8327\n",
      "Epoch 310/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3278 - acc: 0.8635 - val_loss: 0.4026 - val_acc: 0.8207\n",
      "Epoch 311/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3203 - acc: 0.8665 - val_loss: 0.4109 - val_acc: 0.8159\n",
      "Epoch 312/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3304 - acc: 0.8613 - val_loss: 0.3881 - val_acc: 0.8340\n",
      "Epoch 313/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3268 - acc: 0.8644 - val_loss: 0.3819 - val_acc: 0.8332\n",
      "Epoch 314/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3212 - acc: 0.8658 - val_loss: 0.3952 - val_acc: 0.8290\n",
      "Epoch 315/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3554 - acc: 0.8536 - val_loss: 0.3929 - val_acc: 0.8261\n",
      "Epoch 316/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3237 - acc: 0.8651 - val_loss: 0.3879 - val_acc: 0.8296\n",
      "Epoch 317/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3191 - acc: 0.8672 - val_loss: 0.3937 - val_acc: 0.8317\n",
      "Epoch 318/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3528 - acc: 0.8544 - val_loss: 0.3878 - val_acc: 0.8353\n",
      "Epoch 319/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3213 - acc: 0.8665 - val_loss: 0.4473 - val_acc: 0.8296\n",
      "Epoch 320/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4132 - acc: 0.8466 - val_loss: 0.4066 - val_acc: 0.8242\n",
      "Epoch 321/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3552 - acc: 0.8512 - val_loss: 0.4033 - val_acc: 0.8212\n",
      "Epoch 322/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3542 - acc: 0.8526 - val_loss: 0.4005 - val_acc: 0.8283\n",
      "Epoch 323/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3632 - acc: 0.8464 - val_loss: 0.3927 - val_acc: 0.8309\n",
      "Epoch 324/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3434 - acc: 0.8562 - val_loss: 0.3835 - val_acc: 0.8320\n",
      "Epoch 325/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3529 - acc: 0.8536 - val_loss: 0.3833 - val_acc: 0.8322\n",
      "Epoch 326/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3364 - acc: 0.8606 - val_loss: 0.3836 - val_acc: 0.8336\n",
      "Epoch 327/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3294 - acc: 0.8623 - val_loss: 0.3903 - val_acc: 0.8336\n",
      "Epoch 328/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3261 - acc: 0.8639 - val_loss: 0.3878 - val_acc: 0.8293\n",
      "Epoch 329/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3333 - acc: 0.8625 - val_loss: 0.3977 - val_acc: 0.8285\n",
      "Epoch 330/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3641 - acc: 0.8530 - val_loss: 0.3950 - val_acc: 0.8254\n",
      "Epoch 331/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3282 - acc: 0.8622 - val_loss: 0.3902 - val_acc: 0.8307\n",
      "Epoch 332/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3285 - acc: 0.8626 - val_loss: 0.3895 - val_acc: 0.8289\n",
      "Epoch 333/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3284 - acc: 0.8624 - val_loss: 0.3920 - val_acc: 0.8302\n",
      "Epoch 334/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3354 - acc: 0.8611 - val_loss: 0.4028 - val_acc: 0.8273\n",
      "Epoch 335/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3270 - acc: 0.8636 - val_loss: 0.3846 - val_acc: 0.8313\n",
      "Epoch 336/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3581 - acc: 0.8500 - val_loss: 0.3941 - val_acc: 0.8259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3434 - acc: 0.8557 - val_loss: 0.4141 - val_acc: 0.8157\n",
      "Epoch 338/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3700 - acc: 0.8547 - val_loss: 0.4042 - val_acc: 0.8179\n",
      "Epoch 339/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3319 - acc: 0.8608 - val_loss: 0.3838 - val_acc: 0.8370\n",
      "Epoch 340/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3190 - acc: 0.8673 - val_loss: 0.4004 - val_acc: 0.8364\n",
      "Epoch 341/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3376 - acc: 0.8601 - val_loss: 0.3854 - val_acc: 0.8364\n",
      "Epoch 342/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3580 - acc: 0.8568 - val_loss: 0.3938 - val_acc: 0.8308\n",
      "Epoch 343/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3210 - acc: 0.8663 - val_loss: 0.3810 - val_acc: 0.8335\n",
      "Epoch 344/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3365 - acc: 0.8631 - val_loss: 0.3892 - val_acc: 0.8348\n",
      "Epoch 345/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3236 - acc: 0.8652 - val_loss: 0.3919 - val_acc: 0.8330\n",
      "Epoch 346/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3356 - acc: 0.8595 - val_loss: 0.3895 - val_acc: 0.8337\n",
      "Epoch 347/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3259 - acc: 0.8648 - val_loss: 0.4032 - val_acc: 0.8231\n",
      "Epoch 348/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3224 - acc: 0.8651 - val_loss: 0.3857 - val_acc: 0.8319\n",
      "Epoch 349/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3298 - acc: 0.8631 - val_loss: 0.4302 - val_acc: 0.7995\n",
      "Epoch 350/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3352 - acc: 0.8597 - val_loss: 0.3857 - val_acc: 0.8286\n",
      "Epoch 351/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3292 - acc: 0.8629 - val_loss: 0.3870 - val_acc: 0.8294\n",
      "Epoch 352/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3241 - acc: 0.8650 - val_loss: 0.3837 - val_acc: 0.8331\n",
      "Epoch 353/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4010 - acc: 0.8515 - val_loss: 0.3841 - val_acc: 0.8366\n",
      "Epoch 354/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3483 - acc: 0.8533 - val_loss: 0.3900 - val_acc: 0.8282\n",
      "Epoch 355/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3262 - acc: 0.8641 - val_loss: 0.3766 - val_acc: 0.8344\n",
      "Epoch 356/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3716 - acc: 0.8589 - val_loss: 0.4399 - val_acc: 0.7997\n",
      "Epoch 357/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3503 - acc: 0.8506 - val_loss: 0.3957 - val_acc: 0.8334\n",
      "Epoch 358/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3273 - acc: 0.8633 - val_loss: 0.3946 - val_acc: 0.8339\n",
      "Epoch 359/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3863 - acc: 0.8517 - val_loss: 0.4016 - val_acc: 0.8250\n",
      "Epoch 360/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3250 - acc: 0.8635 - val_loss: 0.3914 - val_acc: 0.8359\n",
      "Epoch 361/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3489 - acc: 0.8604 - val_loss: 0.3903 - val_acc: 0.8360\n",
      "Epoch 362/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3257 - acc: 0.8648 - val_loss: 0.3869 - val_acc: 0.8323\n",
      "Epoch 363/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3202 - acc: 0.8666 - val_loss: 0.4949 - val_acc: 0.8104\n",
      "Epoch 364/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3360 - acc: 0.8597 - val_loss: 0.4200 - val_acc: 0.8349\n",
      "Epoch 365/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3493 - acc: 0.8548 - val_loss: 0.3860 - val_acc: 0.8306\n",
      "Epoch 366/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3431 - acc: 0.8560 - val_loss: 0.3811 - val_acc: 0.8312\n",
      "Epoch 367/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3318 - acc: 0.8611 - val_loss: 0.3807 - val_acc: 0.8356\n",
      "Epoch 368/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4044 - acc: 0.8433 - val_loss: 0.4073 - val_acc: 0.8180\n",
      "Epoch 369/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4549 - acc: 0.8370 - val_loss: 0.3979 - val_acc: 0.8227\n",
      "Epoch 370/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3447 - acc: 0.8549 - val_loss: 0.3919 - val_acc: 0.8288\n",
      "Epoch 371/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3300 - acc: 0.8618 - val_loss: 0.3964 - val_acc: 0.8233\n",
      "Epoch 372/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3570 - acc: 0.8506 - val_loss: 0.3890 - val_acc: 0.8275\n",
      "Epoch 373/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3457 - acc: 0.8546 - val_loss: 0.3828 - val_acc: 0.8321\n",
      "Epoch 374/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3379 - acc: 0.8584 - val_loss: 0.4601 - val_acc: 0.7980\n",
      "Epoch 375/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3528 - acc: 0.8545 - val_loss: 0.3975 - val_acc: 0.8312\n",
      "Epoch 376/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3529 - acc: 0.8618 - val_loss: 0.3942 - val_acc: 0.8241\n",
      "Epoch 377/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3719 - acc: 0.8600 - val_loss: 0.4708 - val_acc: 0.7761\n",
      "Epoch 378/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3366 - acc: 0.8588 - val_loss: 0.3940 - val_acc: 0.8270\n",
      "Epoch 379/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3937 - acc: 0.8317 - val_loss: 0.3956 - val_acc: 0.8228\n",
      "Epoch 380/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3693 - acc: 0.8488 - val_loss: 0.3823 - val_acc: 0.8325\n",
      "Epoch 381/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3484 - acc: 0.8530 - val_loss: 0.3831 - val_acc: 0.8347\n",
      "Epoch 382/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3700 - acc: 0.8489 - val_loss: 0.3840 - val_acc: 0.8347\n",
      "Epoch 383/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3300 - acc: 0.8619 - val_loss: 0.3828 - val_acc: 0.8348\n",
      "Epoch 384/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3492 - acc: 0.8560 - val_loss: 0.3834 - val_acc: 0.8340\n",
      "Epoch 385/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3497 - acc: 0.8525 - val_loss: 0.3806 - val_acc: 0.8333\n",
      "Epoch 386/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3327 - acc: 0.8603 - val_loss: 0.3801 - val_acc: 0.8352\n",
      "Epoch 387/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3339 - acc: 0.8605 - val_loss: 0.4189 - val_acc: 0.8125\n",
      "Epoch 388/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3474 - acc: 0.8552 - val_loss: 0.3852 - val_acc: 0.8302\n",
      "Epoch 389/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3329 - acc: 0.8611 - val_loss: 0.3852 - val_acc: 0.8318\n",
      "Epoch 390/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3805 - acc: 0.8428 - val_loss: 0.3851 - val_acc: 0.8322\n",
      "Epoch 391/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3250 - acc: 0.8649 - val_loss: 0.3831 - val_acc: 0.8329\n",
      "Epoch 392/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3792 - acc: 0.8586 - val_loss: 0.3828 - val_acc: 0.8355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3274 - acc: 0.8633 - val_loss: 0.3861 - val_acc: 0.8315\n",
      "Epoch 394/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3346 - acc: 0.8607 - val_loss: 0.3875 - val_acc: 0.8348\n",
      "Epoch 395/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3260 - acc: 0.8646 - val_loss: 0.3875 - val_acc: 0.8334\n",
      "Epoch 396/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3318 - acc: 0.8618 - val_loss: 0.3733 - val_acc: 0.8377\n",
      "Epoch 397/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3480 - acc: 0.8589 - val_loss: 0.3962 - val_acc: 0.8247\n",
      "Epoch 398/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3521 - acc: 0.8523 - val_loss: 0.3770 - val_acc: 0.8352\n",
      "Epoch 399/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3375 - acc: 0.8584 - val_loss: 0.4080 - val_acc: 0.8307\n",
      "Epoch 400/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3287 - acc: 0.8627 - val_loss: 0.3832 - val_acc: 0.8346\n",
      "Epoch 401/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3418 - acc: 0.8567 - val_loss: 0.3800 - val_acc: 0.8325\n",
      "Epoch 402/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3305 - acc: 0.8624 - val_loss: 0.3943 - val_acc: 0.8248\n",
      "Epoch 403/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3285 - acc: 0.8616 - val_loss: 0.3953 - val_acc: 0.8360\n",
      "Epoch 404/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3298 - acc: 0.8629 - val_loss: 0.3774 - val_acc: 0.8383\n",
      "Epoch 405/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3618 - acc: 0.8513 - val_loss: 0.3885 - val_acc: 0.8354\n",
      "Epoch 406/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3232 - acc: 0.8651 - val_loss: 0.3848 - val_acc: 0.8332\n",
      "Epoch 407/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3548 - acc: 0.8508 - val_loss: 0.3843 - val_acc: 0.8358\n",
      "Epoch 408/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3475 - acc: 0.8563 - val_loss: 0.3838 - val_acc: 0.8322\n",
      "Epoch 409/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3394 - acc: 0.8595 - val_loss: 0.3790 - val_acc: 0.8341\n",
      "Epoch 410/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3573 - acc: 0.8506 - val_loss: 0.4084 - val_acc: 0.8152\n",
      "Epoch 411/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3415 - acc: 0.8577 - val_loss: 0.3856 - val_acc: 0.8270\n",
      "Epoch 412/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3343 - acc: 0.8596 - val_loss: 0.4377 - val_acc: 0.8051\n",
      "Epoch 413/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3690 - acc: 0.8442 - val_loss: 0.4049 - val_acc: 0.8269\n",
      "Epoch 414/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3364 - acc: 0.8584 - val_loss: 0.3832 - val_acc: 0.8325\n",
      "Epoch 415/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3886 - acc: 0.8488 - val_loss: 0.3820 - val_acc: 0.8349\n",
      "Epoch 416/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.4490 - acc: 0.8487 - val_loss: 0.3850 - val_acc: 0.8321\n",
      "Epoch 417/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3284 - acc: 0.8621 - val_loss: 0.4241 - val_acc: 0.8030\n",
      "Epoch 418/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3511 - acc: 0.8524 - val_loss: 0.3820 - val_acc: 0.8340\n",
      "Epoch 419/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3353 - acc: 0.8596 - val_loss: 0.3983 - val_acc: 0.8309\n",
      "Epoch 420/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3455 - acc: 0.8550 - val_loss: 0.3853 - val_acc: 0.8326\n",
      "Epoch 421/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3508 - acc: 0.8583 - val_loss: 0.3811 - val_acc: 0.8355\n",
      "Epoch 422/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3328 - acc: 0.8614 - val_loss: 0.3792 - val_acc: 0.8353\n",
      "Epoch 423/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3407 - acc: 0.8570 - val_loss: 0.3869 - val_acc: 0.8299\n",
      "Epoch 424/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3378 - acc: 0.8589 - val_loss: 0.3989 - val_acc: 0.8210\n",
      "Epoch 425/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3353 - acc: 0.8594 - val_loss: 0.3944 - val_acc: 0.8286\n",
      "Epoch 426/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3513 - acc: 0.8528 - val_loss: 0.3808 - val_acc: 0.8328\n",
      "Epoch 427/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3489 - acc: 0.8581 - val_loss: 0.3857 - val_acc: 0.8350\n",
      "Epoch 428/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3485 - acc: 0.8561 - val_loss: 0.3958 - val_acc: 0.8250\n",
      "Epoch 429/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3776 - acc: 0.8562 - val_loss: 0.4322 - val_acc: 0.8175\n",
      "Epoch 430/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3728 - acc: 0.8404 - val_loss: 0.3819 - val_acc: 0.8350\n",
      "Epoch 431/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.6064 - acc: 0.8476 - val_loss: 0.3899 - val_acc: 0.8296\n",
      "Epoch 432/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3432 - acc: 0.8556 - val_loss: 0.3860 - val_acc: 0.8324\n",
      "Epoch 433/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3364 - acc: 0.8585 - val_loss: 0.4189 - val_acc: 0.8135\n",
      "Epoch 434/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3456 - acc: 0.8577 - val_loss: 0.3952 - val_acc: 0.8288\n",
      "Epoch 435/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3620 - acc: 0.8512 - val_loss: 0.3875 - val_acc: 0.8317\n",
      "Epoch 436/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3339 - acc: 0.8596 - val_loss: 0.4781 - val_acc: 0.7717\n",
      "Epoch 437/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3625 - acc: 0.8528 - val_loss: 0.3786 - val_acc: 0.8367\n",
      "Epoch 438/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3922 - acc: 0.8369 - val_loss: 0.4216 - val_acc: 0.8120\n",
      "Epoch 439/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3895 - acc: 0.8388 - val_loss: 0.3885 - val_acc: 0.8263\n",
      "Epoch 440/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3369 - acc: 0.8584 - val_loss: 0.3906 - val_acc: 0.8289\n",
      "Epoch 441/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3413 - acc: 0.8566 - val_loss: 0.4034 - val_acc: 0.8211\n",
      "Epoch 442/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4195 - acc: 0.8469 - val_loss: 0.3917 - val_acc: 0.8273\n",
      "Epoch 443/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3351 - acc: 0.8582 - val_loss: 0.3897 - val_acc: 0.8304\n",
      "Epoch 444/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3521 - acc: 0.8518 - val_loss: 0.3796 - val_acc: 0.8366\n",
      "Epoch 445/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3326 - acc: 0.8610 - val_loss: 0.4003 - val_acc: 0.8306\n",
      "Epoch 446/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3340 - acc: 0.8598 - val_loss: 0.3935 - val_acc: 0.8236\n",
      "Epoch 447/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3617 - acc: 0.8483 - val_loss: 0.3796 - val_acc: 0.8334\n",
      "Epoch 448/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3377 - acc: 0.8590 - val_loss: 0.3897 - val_acc: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3527 - acc: 0.8551 - val_loss: 0.3802 - val_acc: 0.8340\n",
      "Epoch 450/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3417 - acc: 0.8564 - val_loss: 0.3793 - val_acc: 0.8343\n",
      "Epoch 451/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3518 - acc: 0.8546 - val_loss: 0.3814 - val_acc: 0.8307\n",
      "Epoch 452/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3508 - acc: 0.8574 - val_loss: 0.3906 - val_acc: 0.8292\n",
      "Epoch 453/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3553 - acc: 0.8555 - val_loss: 0.3813 - val_acc: 0.8348\n",
      "Epoch 454/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3606 - acc: 0.8564 - val_loss: 0.3793 - val_acc: 0.8365\n",
      "Epoch 455/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3343 - acc: 0.8596 - val_loss: 0.3831 - val_acc: 0.8372\n",
      "Epoch 456/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3481 - acc: 0.8575 - val_loss: 0.4209 - val_acc: 0.8072\n",
      "Epoch 457/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.3322 - acc: 0.8610 - val_loss: 0.3853 - val_acc: 0.8372\n",
      "Epoch 458/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3290 - acc: 0.8634 - val_loss: 0.3787 - val_acc: 0.8373\n",
      "Epoch 459/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.3429 - acc: 0.8564 - val_loss: 0.3831 - val_acc: 0.8326\n",
      "Epoch 460/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3445 - acc: 0.8559 - val_loss: 0.3861 - val_acc: 0.8344\n",
      "Epoch 461/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3345 - acc: 0.8586 - val_loss: 0.3894 - val_acc: 0.8353\n",
      "Epoch 462/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3757 - acc: 0.8454 - val_loss: 0.3925 - val_acc: 0.8282\n",
      "Epoch 463/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3415 - acc: 0.8550 - val_loss: 0.4325 - val_acc: 0.7938\n",
      "Epoch 464/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3305 - acc: 0.8617 - val_loss: 0.3847 - val_acc: 0.8355\n",
      "Epoch 465/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3336 - acc: 0.8603 - val_loss: 0.3990 - val_acc: 0.8169\n",
      "Epoch 466/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3840 - acc: 0.8424 - val_loss: 0.3769 - val_acc: 0.8338\n",
      "Epoch 467/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3374 - acc: 0.8579 - val_loss: 0.3851 - val_acc: 0.8382\n",
      "Epoch 468/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3640 - acc: 0.8487 - val_loss: 0.5250 - val_acc: 0.8306\n",
      "Epoch 469/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3561 - acc: 0.8496 - val_loss: 0.3890 - val_acc: 0.8288\n",
      "Epoch 470/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3375 - acc: 0.8580 - val_loss: 0.3878 - val_acc: 0.8314\n",
      "Epoch 471/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3363 - acc: 0.8582 - val_loss: 0.3883 - val_acc: 0.8316\n",
      "Epoch 472/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3460 - acc: 0.8577 - val_loss: 0.3964 - val_acc: 0.8230\n",
      "Epoch 473/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.4582 - acc: 0.8488 - val_loss: 0.3830 - val_acc: 0.8344\n",
      "Epoch 474/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3387 - acc: 0.8571 - val_loss: 0.3816 - val_acc: 0.8359\n",
      "Epoch 475/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3479 - acc: 0.8524 - val_loss: 0.3989 - val_acc: 0.8254\n",
      "Epoch 476/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3428 - acc: 0.8572 - val_loss: 0.3743 - val_acc: 0.8370\n",
      "Epoch 477/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3540 - acc: 0.8514 - val_loss: 0.3837 - val_acc: 0.8308\n",
      "Epoch 478/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3447 - acc: 0.8568 - val_loss: 0.3900 - val_acc: 0.8273\n",
      "Epoch 479/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3395 - acc: 0.8564 - val_loss: 0.4095 - val_acc: 0.8217\n",
      "Epoch 480/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.4332 - acc: 0.8487 - val_loss: 0.3748 - val_acc: 0.8350\n",
      "Epoch 481/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3337 - acc: 0.8594 - val_loss: 0.3748 - val_acc: 0.8355\n",
      "Epoch 482/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3922 - acc: 0.8457 - val_loss: 0.3826 - val_acc: 0.8387\n",
      "Epoch 483/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3455 - acc: 0.8532 - val_loss: 0.3844 - val_acc: 0.8319\n",
      "Epoch 484/1000\n",
      "249771/249771 [==============================] - 35s 139us/sample - loss: 0.3314 - acc: 0.8614 - val_loss: 0.3776 - val_acc: 0.8380\n",
      "Epoch 485/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3499 - acc: 0.8520 - val_loss: 0.3821 - val_acc: 0.8335\n",
      "Epoch 486/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3688 - acc: 0.8490 - val_loss: 0.3840 - val_acc: 0.8322\n",
      "Epoch 487/1000\n",
      "249771/249771 [==============================] - 35s 139us/sample - loss: 0.3317 - acc: 0.8606 - val_loss: 0.4076 - val_acc: 0.8127\n",
      "Epoch 488/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3407 - acc: 0.8574 - val_loss: 0.3894 - val_acc: 0.8350\n",
      "Epoch 489/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3328 - acc: 0.8605 - val_loss: 0.3848 - val_acc: 0.8318\n",
      "Epoch 490/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.4071 - acc: 0.8558 - val_loss: 0.5424 - val_acc: 0.8075\n",
      "Epoch 491/1000\n",
      "249771/249771 [==============================] - 35s 139us/sample - loss: 0.3618 - acc: 0.8447 - val_loss: 0.3823 - val_acc: 0.8376\n",
      "Epoch 492/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3646 - acc: 0.8460 - val_loss: 0.4145 - val_acc: 0.8104\n",
      "Epoch 493/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3579 - acc: 0.8522 - val_loss: 0.3817 - val_acc: 0.8320\n",
      "Epoch 494/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3587 - acc: 0.8479 - val_loss: 1.2772 - val_acc: 0.8123\n",
      "Epoch 495/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3890 - acc: 0.8343 - val_loss: 0.4313 - val_acc: 0.8014\n",
      "Epoch 496/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3615 - acc: 0.8452 - val_loss: 0.3941 - val_acc: 0.8302\n",
      "Epoch 497/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3438 - acc: 0.8545 - val_loss: 0.3937 - val_acc: 0.8318\n",
      "Epoch 498/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3566 - acc: 0.8520 - val_loss: 0.5705 - val_acc: 0.8296\n",
      "Epoch 499/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.4012 - acc: 0.8436 - val_loss: 0.3882 - val_acc: 0.8349\n",
      "Epoch 500/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3617 - acc: 0.8468 - val_loss: 0.4223 - val_acc: 0.8264\n",
      "Epoch 501/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4513 - acc: 0.8372 - val_loss: 0.3759 - val_acc: 0.8353\n",
      "Epoch 502/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3467 - acc: 0.8531 - val_loss: 0.3775 - val_acc: 0.8370\n",
      "Epoch 503/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3514 - acc: 0.8504 - val_loss: 0.3738 - val_acc: 0.8372\n",
      "Epoch 504/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3528 - acc: 0.8530 - val_loss: 0.4076 - val_acc: 0.8342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3469 - acc: 0.8532 - val_loss: 0.4392 - val_acc: 0.8282\n",
      "Epoch 506/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3502 - acc: 0.8542 - val_loss: 0.4054 - val_acc: 0.8203\n",
      "Epoch 507/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3457 - acc: 0.8542 - val_loss: 0.3785 - val_acc: 0.8341\n",
      "Epoch 508/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3536 - acc: 0.8530 - val_loss: 0.3993 - val_acc: 0.8198\n",
      "Epoch 509/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3347 - acc: 0.8584 - val_loss: 0.3755 - val_acc: 0.8322\n",
      "Epoch 510/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4322 - acc: 0.8359 - val_loss: 0.4098 - val_acc: 0.8107\n",
      "Epoch 511/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3407 - acc: 0.8570 - val_loss: 0.4668 - val_acc: 0.8153\n",
      "Epoch 512/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.4904 - acc: 0.8119 - val_loss: 0.4272 - val_acc: 0.8078\n",
      "Epoch 513/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4053 - acc: 0.8254 - val_loss: 0.4088 - val_acc: 0.8204\n",
      "Epoch 514/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3866 - acc: 0.8359 - val_loss: 0.3753 - val_acc: 0.8359\n",
      "Epoch 515/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3592 - acc: 0.8468 - val_loss: 0.3817 - val_acc: 0.8352\n",
      "Epoch 516/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3565 - acc: 0.8482 - val_loss: 0.3769 - val_acc: 0.8347\n",
      "Epoch 517/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3532 - acc: 0.8515 - val_loss: 0.3959 - val_acc: 0.8159\n",
      "Epoch 518/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3544 - acc: 0.8495 - val_loss: 0.3924 - val_acc: 0.8377\n",
      "Epoch 519/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.3506 - acc: 0.8509 - val_loss: 0.3778 - val_acc: 0.8349\n",
      "Epoch 520/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.3603 - acc: 0.8472 - val_loss: 0.3716 - val_acc: 0.8375\n",
      "Epoch 521/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3547 - acc: 0.8490 - val_loss: 0.3778 - val_acc: 0.8393\n",
      "Epoch 522/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.3952 - acc: 0.8348 - val_loss: 0.3819 - val_acc: 0.8306\n",
      "Epoch 523/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3733 - acc: 0.8420 - val_loss: 0.3979 - val_acc: 0.8273\n",
      "Epoch 524/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3538 - acc: 0.8505 - val_loss: 0.4057 - val_acc: 0.8299\n",
      "Epoch 525/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3564 - acc: 0.8493 - val_loss: 0.3880 - val_acc: 0.8347\n",
      "Epoch 526/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.4589 - acc: 0.8389 - val_loss: 0.3908 - val_acc: 0.8289\n",
      "Epoch 527/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3502 - acc: 0.8507 - val_loss: 0.3993 - val_acc: 0.8370\n",
      "Epoch 528/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3512 - acc: 0.8524 - val_loss: 0.3723 - val_acc: 0.8368\n",
      "Epoch 529/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3729 - acc: 0.8469 - val_loss: 0.6011 - val_acc: 0.8256\n",
      "Epoch 530/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4258 - acc: 0.8320 - val_loss: 0.4311 - val_acc: 0.8088\n",
      "Epoch 531/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3755 - acc: 0.8375 - val_loss: 0.4005 - val_acc: 0.8183\n",
      "Epoch 532/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3929 - acc: 0.8408 - val_loss: 0.4028 - val_acc: 0.8179\n",
      "Epoch 533/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.3790 - acc: 0.8406 - val_loss: 0.3779 - val_acc: 0.8352\n",
      "Epoch 534/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3950 - acc: 0.8466 - val_loss: 0.3878 - val_acc: 0.8269\n",
      "Epoch 535/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.8642 - acc: 0.8373 - val_loss: 0.4077 - val_acc: 0.8190\n",
      "Epoch 536/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3685 - acc: 0.8445 - val_loss: 0.3888 - val_acc: 0.8301\n",
      "Epoch 537/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3569 - acc: 0.8496 - val_loss: 0.3778 - val_acc: 0.8361\n",
      "Epoch 538/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3856 - acc: 0.8436 - val_loss: 0.3841 - val_acc: 0.8318\n",
      "Epoch 539/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3607 - acc: 0.8473 - val_loss: 0.3717 - val_acc: 0.8376\n",
      "Epoch 540/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3540 - acc: 0.8511 - val_loss: 0.4008 - val_acc: 0.8252\n",
      "Epoch 541/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3999 - acc: 0.8475 - val_loss: 0.3725 - val_acc: 0.8368\n",
      "Epoch 542/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3606 - acc: 0.8471 - val_loss: 0.3696 - val_acc: 0.8395\n",
      "Epoch 543/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3601 - acc: 0.8518 - val_loss: 0.3764 - val_acc: 0.8381\n",
      "Epoch 544/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3460 - acc: 0.8531 - val_loss: 0.3755 - val_acc: 0.8360\n",
      "Epoch 545/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3554 - acc: 0.8499 - val_loss: 0.6247 - val_acc: 0.8309\n",
      "Epoch 546/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3620 - acc: 0.8455 - val_loss: 0.4076 - val_acc: 0.8388\n",
      "Epoch 547/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3712 - acc: 0.8478 - val_loss: 0.3734 - val_acc: 0.8406\n",
      "Epoch 548/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3504 - acc: 0.8522 - val_loss: 0.3767 - val_acc: 0.8354\n",
      "Epoch 549/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3807 - acc: 0.8509 - val_loss: 0.4168 - val_acc: 0.8121\n",
      "Epoch 550/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3833 - acc: 0.8313 - val_loss: 0.3750 - val_acc: 0.8365\n",
      "Epoch 551/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3579 - acc: 0.8501 - val_loss: 0.3988 - val_acc: 0.8327\n",
      "Epoch 552/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.4134 - acc: 0.8399 - val_loss: 0.3837 - val_acc: 0.8327\n",
      "Epoch 553/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3468 - acc: 0.8526 - val_loss: 0.3743 - val_acc: 0.8380\n",
      "Epoch 554/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.3552 - acc: 0.8493 - val_loss: 0.3829 - val_acc: 0.8365\n",
      "Epoch 555/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3562 - acc: 0.8496 - val_loss: 0.4038 - val_acc: 0.8331\n",
      "Epoch 556/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3615 - acc: 0.8513 - val_loss: 0.4163 - val_acc: 0.8354\n",
      "Epoch 557/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3426 - acc: 0.8552 - val_loss: 0.4414 - val_acc: 0.8345\n",
      "Epoch 558/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3665 - acc: 0.8463 - val_loss: 0.4975 - val_acc: 0.8382\n",
      "Epoch 559/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3583 - acc: 0.8482 - val_loss: 0.3933 - val_acc: 0.8255\n",
      "Epoch 560/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3700 - acc: 0.8453 - val_loss: 0.3855 - val_acc: 0.8313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3561 - acc: 0.8476 - val_loss: 3.6404 - val_acc: 0.8353\n",
      "Epoch 562/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.4313 - acc: 0.8397 - val_loss: 0.3836 - val_acc: 0.8334\n",
      "Epoch 563/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.4012 - acc: 0.8455 - val_loss: 0.4035 - val_acc: 0.8239\n",
      "Epoch 564/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.3602 - acc: 0.8470 - val_loss: 0.8424 - val_acc: 0.8304\n",
      "Epoch 565/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3589 - acc: 0.8476 - val_loss: 0.4031 - val_acc: 0.8217\n",
      "Epoch 566/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.3628 - acc: 0.8447 - val_loss: 0.4413 - val_acc: 0.8069\n",
      "Epoch 567/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3609 - acc: 0.8459 - val_loss: 0.5490 - val_acc: 0.8388\n",
      "Epoch 568/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3619 - acc: 0.8442 - val_loss: 0.8447 - val_acc: 0.8341\n",
      "Epoch 569/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3644 - acc: 0.8434 - val_loss: 0.8221 - val_acc: 0.8247\n",
      "Epoch 570/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3698 - acc: 0.8416 - val_loss: 0.5026 - val_acc: 0.8291\n",
      "Epoch 571/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3760 - acc: 0.8425 - val_loss: 0.3931 - val_acc: 0.8262\n",
      "Epoch 572/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3595 - acc: 0.8464 - val_loss: 0.5841 - val_acc: 0.8343\n",
      "Epoch 573/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3691 - acc: 0.8472 - val_loss: 0.4551 - val_acc: 0.8384\n",
      "Epoch 574/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3582 - acc: 0.8498 - val_loss: 0.4384 - val_acc: 0.7934\n",
      "Epoch 575/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3923 - acc: 0.8327 - val_loss: 0.4311 - val_acc: 0.8313\n",
      "Epoch 576/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3588 - acc: 0.8475 - val_loss: 0.4644 - val_acc: 0.8250\n",
      "Epoch 577/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3613 - acc: 0.8452 - val_loss: 0.4670 - val_acc: 0.8371\n",
      "Epoch 578/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4049 - acc: 0.8380 - val_loss: 0.4623 - val_acc: 0.7827\n",
      "Epoch 579/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.4062 - acc: 0.8296 - val_loss: 0.4251 - val_acc: 0.8104\n",
      "Epoch 580/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3630 - acc: 0.8450 - val_loss: 0.5232 - val_acc: 0.8274\n",
      "Epoch 581/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3925 - acc: 0.8430 - val_loss: 0.4216 - val_acc: 0.8114\n",
      "Epoch 582/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3973 - acc: 0.8343 - val_loss: 0.3869 - val_acc: 0.8288\n",
      "Epoch 583/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3558 - acc: 0.8478 - val_loss: 0.4187 - val_acc: 0.8104\n",
      "Epoch 584/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3661 - acc: 0.8426 - val_loss: 0.3812 - val_acc: 0.8364\n",
      "Epoch 585/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3865 - acc: 0.8436 - val_loss: 0.3807 - val_acc: 0.8314\n",
      "Epoch 586/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3676 - acc: 0.8432 - val_loss: 0.4107 - val_acc: 0.8103\n",
      "Epoch 587/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.4045 - acc: 0.8296 - val_loss: 0.3944 - val_acc: 0.8259\n",
      "Epoch 588/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3998 - acc: 0.8292 - val_loss: 0.3811 - val_acc: 0.8326\n",
      "Epoch 589/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.4778 - acc: 0.8374 - val_loss: 0.4259 - val_acc: 0.8064\n",
      "Epoch 590/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.3873 - acc: 0.8309 - val_loss: 0.3865 - val_acc: 0.8346\n",
      "Epoch 591/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3748 - acc: 0.8404 - val_loss: 0.3751 - val_acc: 0.8368\n",
      "Epoch 592/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3605 - acc: 0.8467 - val_loss: 0.3961 - val_acc: 0.8254\n",
      "Epoch 593/1000\n",
      "249771/249771 [==============================] - 42s 166us/sample - loss: 0.3778 - acc: 0.8460 - val_loss: 0.3739 - val_acc: 0.8359\n",
      "Epoch 594/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.3920 - acc: 0.8406 - val_loss: 0.3715 - val_acc: 0.8385\n",
      "Epoch 595/1000\n",
      "249771/249771 [==============================] - 43s 174us/sample - loss: 0.5541 - acc: 0.8331 - val_loss: 0.5016 - val_acc: 0.7840\n",
      "Epoch 596/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.4789 - acc: 0.7910 - val_loss: 0.4362 - val_acc: 0.8116\n",
      "Epoch 597/1000\n",
      "249771/249771 [==============================] - 47s 187us/sample - loss: 0.3964 - acc: 0.8311 - val_loss: 0.3851 - val_acc: 0.8293\n",
      "Epoch 598/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3775 - acc: 0.8388 - val_loss: 0.3850 - val_acc: 0.8369\n",
      "Epoch 599/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3805 - acc: 0.8413 - val_loss: 0.3722 - val_acc: 0.8389\n",
      "Epoch 600/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.3638 - acc: 0.8463 - val_loss: 0.3889 - val_acc: 0.8280\n",
      "Epoch 601/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.3749 - acc: 0.8387 - val_loss: 0.3760 - val_acc: 0.8384\n",
      "Epoch 602/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.3722 - acc: 0.8430 - val_loss: 0.3689 - val_acc: 0.8390\n",
      "Epoch 603/1000\n",
      "249771/249771 [==============================] - 42s 169us/sample - loss: 0.3785 - acc: 0.8421 - val_loss: 0.3749 - val_acc: 0.8359\n",
      "Epoch 604/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.3651 - acc: 0.8457 - val_loss: 0.4311 - val_acc: 0.8297\n",
      "Epoch 605/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.3760 - acc: 0.8448 - val_loss: 0.3728 - val_acc: 0.8390\n",
      "Epoch 606/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3667 - acc: 0.8446 - val_loss: 0.4258 - val_acc: 0.8072\n",
      "Epoch 607/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3789 - acc: 0.8385 - val_loss: 0.3751 - val_acc: 0.8361\n",
      "Epoch 608/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.3558 - acc: 0.8484 - val_loss: 0.4270 - val_acc: 0.8368\n",
      "Epoch 609/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.4144 - acc: 0.8394 - val_loss: 0.3701 - val_acc: 0.8394\n",
      "Epoch 610/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3985 - acc: 0.8426 - val_loss: 0.3726 - val_acc: 0.8382\n",
      "Epoch 611/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.3712 - acc: 0.8396 - val_loss: 2.0539 - val_acc: 0.8280\n",
      "Epoch 612/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.4016 - acc: 0.8327 - val_loss: 0.3834 - val_acc: 0.8313\n",
      "Epoch 613/1000\n",
      "249771/249771 [==============================] - 42s 169us/sample - loss: 0.3833 - acc: 0.8388 - val_loss: 0.3773 - val_acc: 0.8399\n",
      "Epoch 614/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.3791 - acc: 0.8396 - val_loss: 0.3678 - val_acc: 0.8412\n",
      "Epoch 615/1000\n",
      "249771/249771 [==============================] - 44s 175us/sample - loss: 0.3780 - acc: 0.8411 - val_loss: 0.4037 - val_acc: 0.8232\n",
      "Epoch 616/1000\n",
      "249771/249771 [==============================] - 43s 170us/sample - loss: 0.3811 - acc: 0.8392 - val_loss: 0.3702 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.3670 - acc: 0.8460 - val_loss: 0.3723 - val_acc: 0.8391\n",
      "Epoch 618/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.3718 - acc: 0.8406 - val_loss: 0.8328 - val_acc: 0.8354\n",
      "Epoch 619/1000\n",
      "249771/249771 [==============================] - 45s 179us/sample - loss: 0.3835 - acc: 0.8372 - val_loss: 0.3712 - val_acc: 0.8376\n",
      "Epoch 620/1000\n",
      "249771/249771 [==============================] - 44s 175us/sample - loss: 0.3557 - acc: 0.8492 - val_loss: 0.3889 - val_acc: 0.8343\n",
      "Epoch 621/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3668 - acc: 0.8430 - val_loss: 0.4148 - val_acc: 0.8363\n",
      "Epoch 622/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3682 - acc: 0.8432 - val_loss: 0.3712 - val_acc: 0.8354\n",
      "Epoch 623/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.3575 - acc: 0.8487 - val_loss: 0.6640 - val_acc: 0.8392\n",
      "Epoch 624/1000\n",
      "249771/249771 [==============================] - 43s 171us/sample - loss: 0.3858 - acc: 0.8380 - val_loss: 0.3692 - val_acc: 0.8388\n",
      "Epoch 625/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.3821 - acc: 0.8420 - val_loss: 0.6307 - val_acc: 0.8038\n",
      "Epoch 626/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.4311 - acc: 0.8315 - val_loss: 0.3994 - val_acc: 0.8230\n",
      "Epoch 627/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.3699 - acc: 0.8430 - val_loss: 0.4344 - val_acc: 0.8048\n",
      "Epoch 628/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3851 - acc: 0.8332 - val_loss: 0.3978 - val_acc: 0.8299\n",
      "Epoch 629/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.4050 - acc: 0.8359 - val_loss: 0.3702 - val_acc: 0.8394\n",
      "Epoch 630/1000\n",
      "249771/249771 [==============================] - 43s 171us/sample - loss: 0.3695 - acc: 0.8453 - val_loss: 0.4396 - val_acc: 0.7987\n",
      "Epoch 631/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3834 - acc: 0.8344 - val_loss: 0.3861 - val_acc: 0.8307\n",
      "Epoch 632/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.4237 - acc: 0.8217 - val_loss: 1.1097 - val_acc: 0.8295\n",
      "Epoch 633/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.4218 - acc: 0.8255 - val_loss: 0.4061 - val_acc: 0.8294\n",
      "Epoch 634/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.3811 - acc: 0.8401 - val_loss: 0.3777 - val_acc: 0.8384\n",
      "Epoch 635/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.3737 - acc: 0.8392 - val_loss: 0.3727 - val_acc: 0.8386\n",
      "Epoch 636/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.3685 - acc: 0.8449 - val_loss: 0.4245 - val_acc: 0.8130\n",
      "Epoch 637/1000\n",
      "249771/249771 [==============================] - 42s 170us/sample - loss: 0.3648 - acc: 0.8428 - val_loss: 0.3819 - val_acc: 0.8339\n",
      "Epoch 638/1000\n",
      "249771/249771 [==============================] - 44s 178us/sample - loss: 0.3813 - acc: 0.8432 - val_loss: 0.3894 - val_acc: 0.8389\n",
      "Epoch 639/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3603 - acc: 0.8466 - val_loss: 0.3768 - val_acc: 0.8389\n",
      "Epoch 640/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.4151 - acc: 0.8450 - val_loss: 0.4420 - val_acc: 0.8048\n",
      "Epoch 641/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.3720 - acc: 0.8403 - val_loss: 0.3872 - val_acc: 0.8345\n",
      "Epoch 642/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.3764 - acc: 0.8417 - val_loss: 0.3880 - val_acc: 0.8273\n",
      "Epoch 643/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.3878 - acc: 0.8352 - val_loss: 0.3765 - val_acc: 0.8338\n",
      "Epoch 644/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3862 - acc: 0.8327 - val_loss: 0.3707 - val_acc: 0.8403\n",
      "Epoch 645/1000\n",
      "249771/249771 [==============================] - 42s 168us/sample - loss: 0.4064 - acc: 0.8255 - val_loss: 0.3765 - val_acc: 0.8355\n",
      "Epoch 646/1000\n",
      "249771/249771 [==============================] - 43s 170us/sample - loss: 0.4003 - acc: 0.8325 - val_loss: 0.3822 - val_acc: 0.8359\n",
      "Epoch 647/1000\n",
      "249771/249771 [==============================] - 44s 175us/sample - loss: 0.3824 - acc: 0.8368 - val_loss: 0.4731 - val_acc: 0.7837\n",
      "Epoch 648/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.3740 - acc: 0.8397 - val_loss: 0.3802 - val_acc: 0.8312\n",
      "Epoch 649/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.3873 - acc: 0.8377 - val_loss: 0.4101 - val_acc: 0.8147\n",
      "Epoch 650/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.3748 - acc: 0.8401 - val_loss: 0.3805 - val_acc: 0.8311\n",
      "Epoch 651/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.3921 - acc: 0.8332 - val_loss: 0.3702 - val_acc: 0.8402\n",
      "Epoch 652/1000\n",
      "249771/249771 [==============================] - 43s 172us/sample - loss: 0.3710 - acc: 0.8424 - val_loss: 0.4190 - val_acc: 0.8165\n",
      "Epoch 653/1000\n",
      "249771/249771 [==============================] - 43s 170us/sample - loss: 0.3985 - acc: 0.8290 - val_loss: 0.3774 - val_acc: 0.8366\n",
      "Epoch 654/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.3677 - acc: 0.8413 - val_loss: 0.3709 - val_acc: 0.8375\n",
      "Epoch 655/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.3901 - acc: 0.8372 - val_loss: 0.4001 - val_acc: 0.8208\n",
      "Epoch 656/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.3704 - acc: 0.8409 - val_loss: 0.3719 - val_acc: 0.8367\n",
      "Epoch 657/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.4441 - acc: 0.8270 - val_loss: 0.4278 - val_acc: 0.8043\n",
      "Epoch 658/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3880 - acc: 0.8303 - val_loss: 0.3780 - val_acc: 0.8324\n",
      "Epoch 659/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4565 - acc: 0.8086 - val_loss: 0.4072 - val_acc: 0.8196\n",
      "Epoch 660/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3792 - acc: 0.8366 - val_loss: 0.3753 - val_acc: 0.8352\n",
      "Epoch 661/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3664 - acc: 0.8416 - val_loss: 0.3792 - val_acc: 0.8331\n",
      "Epoch 662/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3674 - acc: 0.8426 - val_loss: 0.6936 - val_acc: 0.8326\n",
      "Epoch 663/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3992 - acc: 0.8360 - val_loss: 0.3790 - val_acc: 0.8307\n",
      "Epoch 664/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3898 - acc: 0.8339 - val_loss: 0.3707 - val_acc: 0.8367\n",
      "Epoch 665/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3760 - acc: 0.8377 - val_loss: 0.3785 - val_acc: 0.8330\n",
      "Epoch 666/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3796 - acc: 0.8373 - val_loss: 0.3933 - val_acc: 0.8294\n",
      "Epoch 667/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3928 - acc: 0.8376 - val_loss: 0.3751 - val_acc: 0.8366\n",
      "Epoch 668/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3750 - acc: 0.8392 - val_loss: 0.3758 - val_acc: 0.8357\n",
      "Epoch 669/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.3737 - acc: 0.8402 - val_loss: 0.4184 - val_acc: 0.8119\n",
      "Epoch 670/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3872 - acc: 0.8334 - val_loss: 0.3765 - val_acc: 0.8344\n",
      "Epoch 671/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3794 - acc: 0.8352 - val_loss: 0.3971 - val_acc: 0.8260\n",
      "Epoch 672/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3790 - acc: 0.8353 - val_loss: 0.3820 - val_acc: 0.8323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.5964 - acc: 0.8276 - val_loss: 0.3903 - val_acc: 0.8288\n",
      "Epoch 674/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3866 - acc: 0.8328 - val_loss: 0.3773 - val_acc: 0.8345\n",
      "Epoch 675/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3738 - acc: 0.8382 - val_loss: 0.3750 - val_acc: 0.8375\n",
      "Epoch 676/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4482 - acc: 0.8322 - val_loss: 0.3741 - val_acc: 0.8372\n",
      "Epoch 677/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4059 - acc: 0.8290 - val_loss: 0.3822 - val_acc: 0.8346\n",
      "Epoch 678/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3868 - acc: 0.8339 - val_loss: 0.3864 - val_acc: 0.8313\n",
      "Epoch 679/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3745 - acc: 0.8377 - val_loss: 0.3633 - val_acc: 0.8422\n",
      "Epoch 680/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3756 - acc: 0.8391 - val_loss: 0.3712 - val_acc: 0.8399\n",
      "Epoch 681/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3780 - acc: 0.8364 - val_loss: 0.3720 - val_acc: 0.8372\n",
      "Epoch 682/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3907 - acc: 0.8382 - val_loss: 0.4926 - val_acc: 0.7477\n",
      "Epoch 683/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.3656 - acc: 0.8433 - val_loss: 0.3658 - val_acc: 0.8407\n",
      "Epoch 684/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3679 - acc: 0.8408 - val_loss: 0.4625 - val_acc: 0.8298\n",
      "Epoch 685/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3846 - acc: 0.8332 - val_loss: 0.3672 - val_acc: 0.8398\n",
      "Epoch 686/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4031 - acc: 0.8378 - val_loss: 0.3694 - val_acc: 0.8392\n",
      "Epoch 687/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4094 - acc: 0.8263 - val_loss: 0.3871 - val_acc: 0.8317\n",
      "Epoch 688/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3972 - acc: 0.8275 - val_loss: 0.3694 - val_acc: 0.8403\n",
      "Epoch 689/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3720 - acc: 0.8391 - val_loss: 0.3886 - val_acc: 0.8261\n",
      "Epoch 690/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4147 - acc: 0.8305 - val_loss: 0.3984 - val_acc: 0.8265\n",
      "Epoch 691/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3793 - acc: 0.8381 - val_loss: 0.3693 - val_acc: 0.8378\n",
      "Epoch 692/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3831 - acc: 0.8364 - val_loss: 0.3680 - val_acc: 0.8419\n",
      "Epoch 693/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3816 - acc: 0.8357 - val_loss: 0.3869 - val_acc: 0.8269\n",
      "Epoch 694/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3837 - acc: 0.8399 - val_loss: 0.4086 - val_acc: 0.8203\n",
      "Epoch 695/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3870 - acc: 0.8319 - val_loss: 0.3699 - val_acc: 0.8386\n",
      "Epoch 696/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3872 - acc: 0.8368 - val_loss: 0.3718 - val_acc: 0.8392\n",
      "Epoch 697/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3757 - acc: 0.8371 - val_loss: 0.3703 - val_acc: 0.8407\n",
      "Epoch 698/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.4077 - acc: 0.8264 - val_loss: 0.3991 - val_acc: 0.8270\n",
      "Epoch 699/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.4214 - acc: 0.8210 - val_loss: 0.3829 - val_acc: 0.8349\n",
      "Epoch 700/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.4199 - acc: 0.8173 - val_loss: 0.3834 - val_acc: 0.8328\n",
      "Epoch 701/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3736 - acc: 0.8392 - val_loss: 0.3676 - val_acc: 0.8398\n",
      "Epoch 702/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3781 - acc: 0.8386 - val_loss: 0.4192 - val_acc: 0.8185\n",
      "Epoch 703/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3697 - acc: 0.8392 - val_loss: 0.3896 - val_acc: 0.8285\n",
      "Epoch 704/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3694 - acc: 0.8406 - val_loss: 0.3883 - val_acc: 0.8256\n",
      "Epoch 705/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3811 - acc: 0.8354 - val_loss: 0.3797 - val_acc: 0.8334\n",
      "Epoch 706/1000\n",
      "249771/249771 [==============================] - 35s 140us/sample - loss: 0.3738 - acc: 0.8381 - val_loss: 0.3684 - val_acc: 0.8414\n",
      "Epoch 707/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.4009 - acc: 0.8275 - val_loss: 0.3863 - val_acc: 0.8349\n",
      "Epoch 708/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3770 - acc: 0.8388 - val_loss: 0.3682 - val_acc: 0.8394\n",
      "Epoch 709/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3752 - acc: 0.8371 - val_loss: 0.4237 - val_acc: 0.8050\n",
      "Epoch 710/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3910 - acc: 0.8297 - val_loss: 0.3795 - val_acc: 0.8333\n",
      "Epoch 711/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3732 - acc: 0.8378 - val_loss: 0.3669 - val_acc: 0.8403\n",
      "Epoch 712/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3727 - acc: 0.8390 - val_loss: 0.3770 - val_acc: 0.8341\n",
      "Epoch 713/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3728 - acc: 0.8392 - val_loss: 0.3779 - val_acc: 0.8368\n",
      "Epoch 714/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3706 - acc: 0.8414 - val_loss: 0.3727 - val_acc: 0.8385\n",
      "Epoch 715/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.3687 - acc: 0.8405 - val_loss: 0.3684 - val_acc: 0.8398\n",
      "Epoch 716/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3792 - acc: 0.8370 - val_loss: 0.3808 - val_acc: 0.8341\n",
      "Epoch 717/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3747 - acc: 0.8405 - val_loss: 0.4120 - val_acc: 0.8190\n",
      "Epoch 718/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3991 - acc: 0.8307 - val_loss: 0.3954 - val_acc: 0.8230\n",
      "Epoch 719/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3812 - acc: 0.8357 - val_loss: 0.3746 - val_acc: 0.8369\n",
      "Epoch 720/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3653 - acc: 0.8425 - val_loss: 0.3779 - val_acc: 0.8384\n",
      "Epoch 721/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3784 - acc: 0.8372 - val_loss: 0.3736 - val_acc: 0.8361\n",
      "Epoch 722/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3950 - acc: 0.8312 - val_loss: 0.3983 - val_acc: 0.8265\n",
      "Epoch 723/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4035 - acc: 0.8310 - val_loss: 0.3758 - val_acc: 0.8382\n",
      "Epoch 724/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3756 - acc: 0.8384 - val_loss: 0.3779 - val_acc: 0.8353\n",
      "Epoch 725/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.4507 - acc: 0.8265 - val_loss: 0.3761 - val_acc: 0.8374\n",
      "Epoch 726/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4007 - acc: 0.8235 - val_loss: 0.3740 - val_acc: 0.8363\n",
      "Epoch 727/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3843 - acc: 0.8348 - val_loss: 0.3771 - val_acc: 0.8378\n",
      "Epoch 728/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3764 - acc: 0.8370 - val_loss: 0.3728 - val_acc: 0.8395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3923 - acc: 0.8298 - val_loss: 0.3786 - val_acc: 0.8353\n",
      "Epoch 730/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.4282 - acc: 0.8359 - val_loss: 0.3800 - val_acc: 0.8338\n",
      "Epoch 731/1000\n",
      "249771/249771 [==============================] - 36s 142us/sample - loss: 0.3815 - acc: 0.8371 - val_loss: 0.3954 - val_acc: 0.8273\n",
      "Epoch 732/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.4040 - acc: 0.8332 - val_loss: 0.4236 - val_acc: 0.8076\n",
      "Epoch 733/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.3810 - acc: 0.8356 - val_loss: 0.3818 - val_acc: 0.8312\n",
      "Epoch 734/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.4504 - acc: 0.8138 - val_loss: 0.3917 - val_acc: 0.8335\n",
      "Epoch 735/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3913 - acc: 0.8358 - val_loss: 0.7060 - val_acc: 0.6417\n",
      "Epoch 736/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4010 - acc: 0.8262 - val_loss: 0.3685 - val_acc: 0.8420\n",
      "Epoch 737/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.4026 - acc: 0.8351 - val_loss: 0.3906 - val_acc: 0.8273\n",
      "Epoch 738/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4503 - acc: 0.8068 - val_loss: 0.3724 - val_acc: 0.8380\n",
      "Epoch 739/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3856 - acc: 0.8344 - val_loss: 0.4472 - val_acc: 0.7945\n",
      "Epoch 740/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3914 - acc: 0.8282 - val_loss: 0.3775 - val_acc: 0.8378\n",
      "Epoch 741/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.4119 - acc: 0.8341 - val_loss: 0.3914 - val_acc: 0.8294\n",
      "Epoch 742/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3777 - acc: 0.8362 - val_loss: 0.3933 - val_acc: 0.8294\n",
      "Epoch 743/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.4772 - acc: 0.8131 - val_loss: 0.4494 - val_acc: 0.8051\n",
      "Epoch 744/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3970 - acc: 0.8309 - val_loss: 0.3916 - val_acc: 0.8273\n",
      "Epoch 745/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.3822 - acc: 0.8334 - val_loss: 0.3938 - val_acc: 0.8281\n",
      "Epoch 746/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3760 - acc: 0.8379 - val_loss: 0.3750 - val_acc: 0.8353\n",
      "Epoch 747/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4375 - acc: 0.8163 - val_loss: 0.5380 - val_acc: 0.7714\n",
      "Epoch 748/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4175 - acc: 0.8228 - val_loss: 0.3858 - val_acc: 0.8307\n",
      "Epoch 749/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3822 - acc: 0.8350 - val_loss: 0.3761 - val_acc: 0.8371\n",
      "Epoch 750/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3938 - acc: 0.8322 - val_loss: 0.3970 - val_acc: 0.8294\n",
      "Epoch 751/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.3942 - acc: 0.8332 - val_loss: 0.3742 - val_acc: 0.8358\n",
      "Epoch 752/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4018 - acc: 0.8275 - val_loss: 0.4077 - val_acc: 0.8213\n",
      "Epoch 753/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3848 - acc: 0.8341 - val_loss: 0.3738 - val_acc: 0.8381\n",
      "Epoch 754/1000\n",
      "249771/249771 [==============================] - 36s 143us/sample - loss: 0.3791 - acc: 0.8369 - val_loss: 0.3775 - val_acc: 0.8355\n",
      "Epoch 755/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4052 - acc: 0.8286 - val_loss: 0.3959 - val_acc: 0.8216\n",
      "Epoch 756/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3831 - acc: 0.8362 - val_loss: 0.3746 - val_acc: 0.8368\n",
      "Epoch 757/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3828 - acc: 0.8351 - val_loss: 0.3842 - val_acc: 0.8327\n",
      "Epoch 758/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.3827 - acc: 0.8332 - val_loss: 0.3699 - val_acc: 0.8384\n",
      "Epoch 759/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3736 - acc: 0.8380 - val_loss: 0.3641 - val_acc: 0.8421\n",
      "Epoch 760/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3757 - acc: 0.8370 - val_loss: 0.3715 - val_acc: 0.8347\n",
      "Epoch 761/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.3751 - acc: 0.8389 - val_loss: 0.4025 - val_acc: 0.8410\n",
      "Epoch 762/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.4058 - acc: 0.8236 - val_loss: 0.3723 - val_acc: 0.8386\n",
      "Epoch 763/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3766 - acc: 0.8381 - val_loss: 0.3725 - val_acc: 0.8363\n",
      "Epoch 764/1000\n",
      "249771/249771 [==============================] - 35s 141us/sample - loss: 0.3825 - acc: 0.8365 - val_loss: 0.3844 - val_acc: 0.8315\n",
      "Epoch 765/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4148 - acc: 0.8286 - val_loss: 0.4424 - val_acc: 0.8107\n",
      "Epoch 766/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.4059 - acc: 0.8241 - val_loss: 0.3871 - val_acc: 0.8273\n",
      "Epoch 767/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3796 - acc: 0.8366 - val_loss: 0.4064 - val_acc: 0.8224\n",
      "Epoch 768/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3988 - acc: 0.8317 - val_loss: 0.3944 - val_acc: 0.8256\n",
      "Epoch 769/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.4029 - acc: 0.8239 - val_loss: 0.4372 - val_acc: 0.7925\n",
      "Epoch 770/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.4202 - acc: 0.8201 - val_loss: 0.3795 - val_acc: 0.8371\n",
      "Epoch 771/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.4281 - acc: 0.8191 - val_loss: 0.4225 - val_acc: 0.8211\n",
      "Epoch 772/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3881 - acc: 0.8338 - val_loss: 0.3817 - val_acc: 0.8346\n",
      "Epoch 773/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3977 - acc: 0.8284 - val_loss: 0.3813 - val_acc: 0.8392\n",
      "Epoch 774/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4166 - acc: 0.8235 - val_loss: 0.3982 - val_acc: 0.8270\n",
      "Epoch 775/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4160 - acc: 0.8229 - val_loss: 0.4420 - val_acc: 0.8016\n",
      "Epoch 776/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4105 - acc: 0.8202 - val_loss: 0.3797 - val_acc: 0.8388\n",
      "Epoch 777/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.4410 - acc: 0.8139 - val_loss: 0.4112 - val_acc: 0.8233\n",
      "Epoch 778/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.3985 - acc: 0.8281 - val_loss: 0.4049 - val_acc: 0.8245\n",
      "Epoch 779/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3932 - acc: 0.8316 - val_loss: 0.3766 - val_acc: 0.8378\n",
      "Epoch 780/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.3875 - acc: 0.8338 - val_loss: 0.3743 - val_acc: 0.8370\n",
      "Epoch 781/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.3904 - acc: 0.8317 - val_loss: 0.3910 - val_acc: 0.8323\n",
      "Epoch 782/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.4577 - acc: 0.8076 - val_loss: 0.4646 - val_acc: 0.7886\n",
      "Epoch 783/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.4164 - acc: 0.8160 - val_loss: 0.3788 - val_acc: 0.8345\n",
      "Epoch 784/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.3813 - acc: 0.8373 - val_loss: 0.4086 - val_acc: 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3962 - acc: 0.8296 - val_loss: 0.4016 - val_acc: 0.8312\n",
      "Epoch 786/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.4690 - acc: 0.8182 - val_loss: 0.3777 - val_acc: 0.8367\n",
      "Epoch 787/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.3760 - acc: 0.8382 - val_loss: 0.3716 - val_acc: 0.8370\n",
      "Epoch 788/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.3983 - acc: 0.8298 - val_loss: 0.3776 - val_acc: 0.8362\n",
      "Epoch 789/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.4045 - acc: 0.8300 - val_loss: 0.3922 - val_acc: 0.8313\n",
      "Epoch 790/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.3947 - acc: 0.8285 - val_loss: 0.3971 - val_acc: 0.8274\n",
      "Epoch 791/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.5755 - acc: 0.7341 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 792/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 793/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 794/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 795/1000\n",
      "249771/249771 [==============================] - 36s 146us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 796/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 797/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 798/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 799/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 800/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 801/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 802/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 803/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 804/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 805/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 806/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 807/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 808/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 809/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 810/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 811/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 812/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 813/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 814/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 815/1000\n",
      "249771/249771 [==============================] - 37s 146us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 816/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 817/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 818/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 819/1000\n",
      "249771/249771 [==============================] - 36s 145us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 820/1000\n",
      "249771/249771 [==============================] - 35s 142us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 821/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 822/1000\n",
      "249771/249771 [==============================] - 37s 148us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 823/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 824/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 825/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 826/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 827/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 828/1000\n",
      "249771/249771 [==============================] - 37s 147us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 829/1000\n",
      "249771/249771 [==============================] - 36s 144us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 830/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 831/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 832/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 833/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 834/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 835/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 836/1000\n",
      "249771/249771 [==============================] - 38s 150us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 837/1000\n",
      "249771/249771 [==============================] - 37s 150us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 838/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 839/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 840/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "249771/249771 [==============================] - 37s 149us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 842/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 843/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 844/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 845/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 846/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5979 - val_acc: 0.7152\n",
      "Epoch 847/1000\n",
      "249771/249771 [==============================] - 43s 173us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 848/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 849/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 850/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 851/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 852/1000\n",
      "249771/249771 [==============================] - 42s 170us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 853/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 854/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 855/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 856/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 857/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 858/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 859/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 860/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 861/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 862/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 863/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 864/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 865/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 866/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 867/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 868/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 869/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 870/1000\n",
      "249771/249771 [==============================] - 43s 170us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 871/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 872/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 873/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 874/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 875/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 876/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5977 - val_acc: 0.7152\n",
      "Epoch 877/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 878/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 879/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 880/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 881/1000\n",
      "249771/249771 [==============================] - 38s 151us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 882/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 883/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 884/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 885/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 886/1000\n",
      "249771/249771 [==============================] - 38s 152us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 887/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 888/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 889/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 890/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 891/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 892/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 893/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 894/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 895/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 896/1000\n",
      "249771/249771 [==============================] - 38s 153us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 898/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 899/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 900/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 901/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 902/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 903/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 904/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 905/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 906/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 907/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 908/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 909/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 910/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 911/1000\n",
      "249771/249771 [==============================] - 41s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 912/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 913/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 914/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 915/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 916/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 917/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 918/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 919/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 920/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 921/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 922/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 923/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 924/1000\n",
      "249771/249771 [==============================] - 43s 171us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 925/1000\n",
      "249771/249771 [==============================] - 42s 166us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5977 - val_acc: 0.7152\n",
      "Epoch 926/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 927/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 928/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 929/1000\n",
      "249771/249771 [==============================] - 41s 165us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 930/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 931/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 932/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 933/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 934/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 935/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 936/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 937/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 938/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 939/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 940/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 941/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 942/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 943/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 944/1000\n",
      "249771/249771 [==============================] - 43s 170us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 945/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 946/1000\n",
      "249771/249771 [==============================] - 44s 178us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 947/1000\n",
      "249771/249771 [==============================] - 42s 167us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 948/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 949/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 950/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 951/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 952/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 954/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 955/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 956/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 957/1000\n",
      "249771/249771 [==============================] - 40s 159us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 958/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5966 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 959/1000\n",
      "249771/249771 [==============================] - 39s 157us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 960/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 961/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 962/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 963/1000\n",
      "249771/249771 [==============================] - 38s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 964/1000\n",
      "249771/249771 [==============================] - 39s 155us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 965/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 966/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 967/1000\n",
      "249771/249771 [==============================] - 39s 154us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 968/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 969/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 970/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 971/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 972/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 973/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 974/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 975/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 976/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 977/1000\n",
      "249771/249771 [==============================] - 39s 156us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 978/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 979/1000\n",
      "249771/249771 [==============================] - 39s 158us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 980/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 981/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 982/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 983/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 984/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 985/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 986/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 987/1000\n",
      "249771/249771 [==============================] - 40s 161us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 988/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 989/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 990/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 991/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 992/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5976 - val_acc: 0.7152\n",
      "Epoch 993/1000\n",
      "249771/249771 [==============================] - 41s 164us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 994/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 995/1000\n",
      "249771/249771 [==============================] - 40s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 996/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 997/1000\n",
      "249771/249771 [==============================] - 40s 160us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 998/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 999/1000\n",
      "249771/249771 [==============================] - 41s 163us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n",
      "Epoch 1000/1000\n",
      "249771/249771 [==============================] - 41s 162us/sample - loss: 0.5965 - acc: 0.7162 - val_loss: 0.5975 - val_acc: 0.7152\n"
     ]
    }
   ],
   "source": [
    "#Time to fit the model.\n",
    "fit = model.fit(X, y, batch_size=32, epochs=1000, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5cb7a4c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fit.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(fit.history['acc'])\n",
    "plt.plot(fit.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONCLUSIONS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
